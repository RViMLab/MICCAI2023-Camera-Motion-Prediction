{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit1b62a264e17d42af939496f2c9cc110f",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Homography Regression Qualitative Evaluation\n",
    "A homography regression network that was trained on synthetically generated camera motion data is evaluated on data where camera motion occurs naturally.\n",
    "\n",
    "## Load Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running with CUDA backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from utils.io import load_yaml\n",
    "from lightning_modules import DeepImageHomographyEstimationModuleBackbone\n",
    "\n",
    "# load best model\\n\",\n",
    "prefix = '/home/martin/Tresors/homography_imitation_learning_logs/deep_image_homography_estimation_backbone/version_0'\n",
    "configs = load_yaml(os.path.join(prefix, 'configs.yml'))\n",
    "model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=19.ckpt'), shape=configs['model']['shape'])\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print('Running with CUDA backend.')\n",
    "    device = 'cuda'\n",
    "\n",
    "model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and evaluate model on\n",
    "#   - with motion dataset\n",
    "#   - cholec80\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from kornia import warp_perspective, tensor_to_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from datasets import ImageSequenceDataset\n",
    "from utils.processing import image_edges, four_pt_to_matrix_homography_representation"
   ]
  },
  {
   "source": [
    "## With Camera Motion - DaVinci"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion dataset\n",
    "prefix = '/media/martin/Samsung_T5/data/endoscopic_data/camera_motion_separated_png/with_camera_motion'\n",
    "df_name = 'log_with_camera_motion_seq_len_2.pkl'\n",
    "df = pd.read_pickle(os.path.join(prefix, df_name))\n",
    "ds = ImageSequenceDataset(df, prefix, ToTensor())\n",
    "\n",
    "for img_seq in ds:\n",
    "    img_seq[0], img_seq[1] = img_seq[0].to(device), img_seq[1].to(device)\n",
    "    duv = model(img_seq[0].unsqueeze(0), img_seq[1].unsqueeze(0))\n",
    "\n",
    "    uv = image_edges(img_seq[0].unsqueeze(0))\n",
    "    H = four_pt_to_matrix_homography_representation(uv, duv)\n",
    "\n",
    "    wrp = warp_perspective(img_seq[0].unsqueeze(0), torch.inverse(H), img_seq[0].shape[-2:])\n",
    "    \n",
    "    wrp = tensor_to_image(wrp)\n",
    "    img0 = tensor_to_image(img_seq[0])\n",
    "    img1 = tensor_to_image(img_seq[1])\n",
    "\n",
    "    cv2.imshow('img1', img1)\n",
    "    cv2.imshow('wrp', wrp)\n",
    "    cv2.imshow('L1 img0, img1', abs(img0-img1))\n",
    "    cv2.imshow('L1 img1, wrp', abs(img1-wrp))\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "source": [
    "## With Camera Motion - Cholec80\n",
    "### Image Shapes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cholec80, analyze image shape\n",
    "import os\n",
    "import cv2\n",
    "from utils.io import load_yaml\n",
    "\n",
    "cholec_configs = load_yaml('configs/cholec80_transforms.yml')\n",
    "\n",
    "database_prefix = '/media/martin/Samsung_T5/data/endoscopic_data'\n",
    "\n",
    "for database in cholec_configs['databases']:\n",
    "    path = os.path.join(database_prefix, database['prefix'])\n",
    "    for file in database['videos']['files']:\n",
    "        path = os.path.join(database_prefix, database['prefix'], database['videos']['prefix'], file)\n",
    "        vc = cv2.VideoCapture(path)\n",
    "\n",
    "        _, img = vc.read()\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey()"
   ]
  },
  {
   "source": [
    "### Homography Estimation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cholec80, evaluate model\n",
    "import pandas as pd\n",
    "from torchvision.transforms import ToTensor\n",
    "from datasets import ImageSequenceDataset\n",
    "\n",
    "prefix = '/media/martin/Samsung_T5/data/endoscopic_data/tmp'\n",
    "df_name = 'cholec80_seq_len_2.pkl'\n",
    "df = pd.read_pickle(os.path.join(prefix, df_name))\n",
    "\n",
    "ds = ImageSequenceDataset(df, prefix, ToTensor())\n",
    "\n",
    "for img_seq in ds:\n",
    "    img_seq[0], img_seq[1] = img_seq[0].to(device), img_seq[1].to(device)\n",
    "    duv = model(img_seq[0].unsqueeze(0), img_seq[1].unsqueeze(0))\n",
    "\n",
    "    uv = image_edges(img_seq[0].unsqueeze(0))\n",
    "    H = four_pt_to_matrix_homography_representation(uv, duv)\n",
    "\n",
    "    wrp = warp_perspective(img_seq[0].unsqueeze(0), torch.inverse(H), img_seq[0].shape[-2:])\n",
    "\n",
    "    wrp = tensor_to_image(wrp)\n",
    "    img0 = tensor_to_image(img_seq[0])\n",
    "    img1 = tensor_to_image(img_seq[1])\n",
    "\n",
    "    cv2.imshow('img1', img1)\n",
    "    cv2.imshow('wrp', wrp)\n",
    "    cv2.imshow('L1 img0, img1', abs(img0-img1))\n",
    "    cv2.imshow('L1 img1, wrp', abs(img1-wrp))\n",
    "    cv2.waitKey()"
   ]
  }
 ]
}