{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit1b62a264e17d42af939496f2c9cc110f",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Homography Regression Qualitative Evaluation\n",
    "A homography regression network that was trained on synthetically generated camera motion data is evaluated on data where camera motion occurs naturally.\n",
    "\n",
    "## Load Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running with CUDA backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from kornia import warp_perspective, tensor_to_image\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from datasets import ImageSequenceDataset\n",
    "from lightning_modules import DeepImageHomographyEstimationModuleBackbone\n",
    "from utils.io import load_yaml\n",
    "from utils.processing import image_edges, four_pt_to_matrix_homography_representation\n",
    "from utils.viz import yt_alpha_blend\n",
    "\n",
    "# load best model\\n\",\n",
    "prefix = '/home/martin/Tresors/homography_imitation_learning_logs/deep_image_homography_estimation_backbone/version_0'\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/unsupervised_deep_homography_estimation_backbone/version_0'\n",
    "configs = load_yaml(os.path.join(prefix, 'configs.yml'))\n",
    "model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=19.ckpt'), shape=configs['model']['shape'])\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print('Running with CUDA backend.')\n",
    "    device = 'cuda'\n",
    "\n",
    "model.to(device)\n",
    "model = model.eval()\n",
    "\n",
    "# create dataset and evaluate model on\n",
    "#   - with motion dataset\n",
    "#   - cholec80\n",
    "def eval(img_seq, init_frame=None, init=False, h_memory=torch.eye(3).unsqueeze(0), shape=(640, 480), show_image=True, track=False):\n",
    "    img_seq[0], img_seq[1] = img_seq[0].to(device).squeeze(), img_seq[1].to(device).squeeze()\n",
    "    duv = model(img_seq[0].unsqueeze(0), img_seq[1].unsqueeze(0))\n",
    "\n",
    "    uv = image_edges(img_seq[0].unsqueeze(0))\n",
    "    H = four_pt_to_matrix_homography_representation(uv, duv)\n",
    "\n",
    "    wrp = warp_perspective(img_seq[0].unsqueeze(0), torch.inverse(H), img_seq[0].shape[-2:])\n",
    "\n",
    "    wrp = cv2.resize(tensor_to_image(wrp), shape)[...,::-1]\n",
    "    img0 = cv2.resize(tensor_to_image(img_seq[0]), shape)[...,::-1]\n",
    "    img1 = cv2.resize(tensor_to_image(img_seq[1]), shape)[...,::-1]\n",
    "\n",
    "    l1_img0_img1 = abs(img1-img0)\n",
    "    l1_img1_wrp  = abs(img1-wrp)\n",
    "    blend_img0_img1 = yt_alpha_blend(img1, img0)\n",
    "    blend_img1_wrp  = yt_alpha_blend(img1, wrp)\n",
    "\n",
    "    if track:\n",
    "        if not init:\n",
    "            init_frame = cv2.resize(tensor_to_image(img_seq[0]), shape)[...,::-1]\n",
    "            init = True\n",
    "\n",
    "        h_memory = h_memory.matmul(H.detach()) # inverse order\n",
    "\n",
    "        wrp_memory = warp_perspective(img_seq[1].unsqueeze(0), h_memory, img_seq[1].shape[-2:])\n",
    "        wrp_memory = cv2.resize(tensor_to_image(wrp_memory), shape)[...,::-1]\n",
    "\n",
    "        blend_wrp_memory_init_frame  = yt_alpha_blend(wrp_memory, init_frame)\n",
    "        top_row    = np.concatenate([img0, l1_img0_img1, blend_img0_img1], axis=1)\n",
    "        bottom_row = np.concatenate([blend_wrp_memory_init_frame,  l1_img1_wrp,  blend_img1_wrp], axis=1)\n",
    "    else:\n",
    "        top_row    = np.concatenate([img0, l1_img0_img1, blend_img0_img1], axis=1)\n",
    "        bottom_row = np.concatenate([img1,  l1_img1_wrp,  blend_img1_wrp], axis=1)\n",
    "    composite = np.concatenate([top_row, bottom_row], axis=0)\n",
    "\n",
    "    if show_image:\n",
    "        cv2.imshow('composite', composite)\n",
    "        cv2.waitKey()\n",
    "\n",
    "    if track:\n",
    "        return composite, init_frame, init, h_memory\n",
    "    else:\n",
    "        return composite\n"
   ]
  },
  {
   "source": [
    "## With Camera Motion - DaVinci"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion dataset\n",
    "prefix = '/media/martin/Samsung_T5/data/endoscopic_data/camera_motion_separated_png/with_camera_motion'\n",
    "df_name = 'log_with_camera_motion_seq_len_2.pkl'\n",
    "df = pd.read_pickle(os.path.join(prefix, df_name))\n",
    "ds = ImageSequenceDataset(df, prefix, ToTensor())\n",
    "dl = DataLoader(ds, batch_size=1)\n",
    "\n",
    "init_frame = None\n",
    "init = False\n",
    "h_memory = torch.eye(3, device=device)\n",
    "for img_seq in dl: \n",
    "    composite, init_frame, init, h_memory = eval(img_seq, init_frame, init, h_memory, show_image=True, track=True)"
   ]
  },
  {
   "source": [
    "## With Camera Motion - Cholec80\n",
    "### Image Shapes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cholec80, analyze image shape\n",
    "cholec_configs = load_yaml('configs/cholec80_transforms.yml')\n",
    "\n",
    "database_prefix = '/media/martin/Samsung_T5/data/endoscopic_data'\n",
    "\n",
    "for database in cholec_configs['databases']:\n",
    "    path = os.path.join(database_prefix, database['prefix'])\n",
    "    for file in database['videos']['files']:\n",
    "        path = os.path.join(database_prefix, database['prefix'], database['videos']['prefix'], file)\n",
    "        vc = cv2.VideoCapture(path)\n",
    "\n",
    "        _, img = vc.read()\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey()"
   ]
  },
  {
   "source": [
    "### Homography Estimation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cholec80, evaluate model\n",
    "prefix = '/media/martin/Samsung_T5/data/endoscopic_data/tmp'\n",
    "df_name = 'cholec80_seq_len_2.pkl'\n",
    "df = pd.read_pickle(os.path.join(prefix, df_name))\n",
    "ds = ImageSequenceDataset(df, prefix, ToTensor())\n",
    "dl = DataLoader(ds, batch_size=1)\n",
    "\n",
    "# 44.7 s ± 419 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) (divide by 1000)\n",
    "# in between ~ 22 and 50 fps\n",
    "init_frame = None\n",
    "init = False\n",
    "h_memory = torch.eye(3, device=device)\n",
    "track = False\n",
    "for img_seq in dl: \n",
    "    if track:\n",
    "        composite, init_frame, init, h_memory = eval(img_seq, init_frame, init, h_memory, show_image=True, track=track)\n",
    "    else:\n",
    "        composite = eval(img_seq, shape=(320, 240), show_image=True)"
   ]
  },
  {
   "source": [
    "#### Create Video"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cholec80, evaluate model\n",
    "prefix = '/media/martin/Samsung_T5/data/endoscopic_data/tmp'\n",
    "df_name = 'cholec80_seq_len_2.pkl'\n",
    "df = pd.read_pickle(os.path.join(prefix, df_name))\n",
    "ds = ImageSequenceDataset(df, prefix, ToTensor())\n",
    "dl = DataLoader(ds, batch_size=1)\n",
    "\n",
    "# 44.7 s ± 419 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) (divide by 1000)\n",
    "# in between ~ 22 and 50 fps\n",
    "\n",
    "shape = eval(next(iter(dl)), show_image=False, track=False).shape[:2]\n",
    "out = cv2.VideoWriter('composite_stride_10.avi', fourcc=cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps=25, frameSize=(shape[1], shape[0]))\n",
    "\n",
    "init_frame = None\n",
    "init = False\n",
    "h_memory = torch.eye(3, device=device).unsqueeze(0)\n",
    "for img_seq in dl: \n",
    "    composite, init_frame, init, h_memory = eval(img_seq, init_frame, init, h_memory, show_image=False, track=True)\n",
    "    composite = (composite*255).astype(np.uint8)\n",
    "    out.write(composite)\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "source": [
    "# Image Reflections\n",
    "Generate masks of reflections by thresholding images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # motion dataset\n",
    "# prefix = '/media/martin/Samsung_T5/data/endoscopic_data/camera_motion_separated_png/without_camera_motion'\n",
    "# df_name = 'log_without_camera_motion_seq_len_2.pkl'\n",
    "# df = pd.read_pickle(os.path.join(prefix, df_name))\n",
    "# ds = ImageSequenceDataset(df, prefix, ToTensor())\n",
    "# dl = DataLoader(ds, batch_size=1)\n",
    "\n",
    "# for img_seq in dl:\n",
    "#     img0 = tensor_to_image(img_seq[0])\n",
    "#     cv2.imshow('img0', img0)\n",
    "#     cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}