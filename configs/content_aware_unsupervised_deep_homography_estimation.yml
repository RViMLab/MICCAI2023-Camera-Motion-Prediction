experiment: 'content_aware_unsupervised_deep_homography_estimation'
lightning_module: 'ContentAwareUnsupervisedDeepHomographyEstimationModule'
lightning_data_module: 'ImagePairHomographyDataModule'
trainer:
    gpus: 1
    max_epochs: 20
    log_every_n_steps: 100
    limit_train_batches: 1.0
    limit_val_batches: 1.0
    limit_test_batches: 1.0
    fast_dev_run: False
    profiler: False
    distributed_backend: null
data:
    pkl_name: 'light_log_without_camera_motion.pkl'
    pkl_path: 'camera_motion_separated_png/without_camera_motion'
    train_split: 0.8
    random_state: 42
    batch_size: 16
    num_workers: 4
    rho: 64
    crp_shape: [480, 640]
    p0: 0.05
    seq_len: 2
    unsupervised: True
    train_transforms: # augmentations from imgaug https://imgaug.readthedocs.io/en/latest/source/overview_of_augmenters.html
        - {'chance': 1.0, 'module': 'imgaug.augmenters',                'type': 'Resize',             'kwargs': {'size': {'height': 612, 'width': 816}}}
        - {'chance': 0.1, 'module': 'imgaug.augmenters',                'type': 'Grayscale',          'kwargs': {}}
        - {'chance': 0.5, 'module': 'imgaug.augmenters',                'type': 'HorizontalFlip',     'kwargs': {}}
        - {'chance': 0.5, 'module': 'imgaug.augmenters',                'type': 'VerticalFlip',       'kwargs': {}}
        - {'chance': 0.2, 'module': 'imgaug.augmenters',                'type': 'Crop',               'kwargs': {'percent': !!python/tuple [0., 0.4]}}
        - {'chance': 0.3, 'module': 'imgaug.augmenters',                'type': 'MultiplyBrightness', 'kwargs': {'mul': [0.5, 1.5]}}
        - {'chance': 0.1, 'module': 'imgaug.augmenters',                'type': 'GaussianBlur',       'kwargs': {}}
        - {'chance': 0.1, 'module': 'imgaug.augmenters.imgcorruptlike', 'type': 'Fog',                'kwargs': {'severity': 2}}
        - {'chance': 0.2, 'module': 'imgaug.augmenters.imgcorruptlike', 'type': 'Contrast',           'kwargs': {'severity': 1}}
    val_transforms: null
model:
    shape: [3, 480, 640]
    lam: 2.0
    mu: 0.01
    pre_train_epochs: 4
    lr: 1.e-4
    betas: [0.9, 0.999]
    log_n_steps: 1000
