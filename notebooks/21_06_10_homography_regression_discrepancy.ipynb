{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit1b62a264e17d42af939496f2c9cc110f",
   "display_name": "Python 3.7.6 64-bit ('hil': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "efe34164bbb50e70fce224383f42acab6a26dd9dc9fafc86c4e503220a8c76a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Create Dataloader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotmap import DotMap\n",
    "\n",
    "from utils.io import load_yaml\n",
    "from utils.io import load_pickle, save_pickle\n",
    "from utils.transforms import anyDictListToCompose\n",
    "from lightning_data_modules import VideoDataModule\n",
    "\n",
    "server = 'local'\n",
    "server = DotMap(load_yaml('../config/servers.yml')[server])\n",
    "\n",
    "meta_df_name = 'cholec80_retransforms.pkl'\n",
    "meta_df = pd.read_pickle(os.path.join(server.config.location, meta_df_name))\n",
    "meta_df.aug_transforms = None  # no transforms for evaluation\n",
    "\n",
    "# load cholec80\n",
    "prefix = server.database.location\n",
    "clip_length_in_frames = 2\n",
    "frames_between_clips = 1\n",
    "frame_rate = 5\n",
    "train_split = 0.5\n",
    "batch_size = 1\n",
    "num_workers = 8\n",
    "random_state = 42\n",
    "\n",
    "# None if not initialized\n",
    "test_md_name = 'cholec80_homography_regression_discrepancy_test_md_frame_rate_{}.pkl'.format(frame_rate)\n",
    "\n",
    "try:\n",
    "    test_md = load_pickle(os.path.join(server.config.location, test_md_name))\n",
    "except:\n",
    "    test_md = None\n",
    "\n",
    "dm = VideoDataModule(\n",
    "    meta_df,\n",
    "    prefix=prefix,\n",
    "    clip_length_in_frames=clip_length_in_frames,\n",
    "    frames_between_clips=frames_between_clips   ,\n",
    "    frame_rate=frame_rate,\n",
    "    train_split=train_split,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    random_state=random_state,\n",
    "    test_metadata=test_md\n",
    ")\n",
    "\n",
    "_, _, test_md = dm.setup('test')\n",
    "\n",
    "# store metadata\n",
    "if test_md:\n",
    "    save_pickle(os.path.join(server.config.location, test_md_name), test_md)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('../config/cholec80_transforms.pkl')\n",
    "df.pre_transforms = df.pre_transforms.apply(lambda x: [\n",
    "    x[0],\n",
    "    {\n",
    "        'module': 'torchvision.transforms',\n",
    "        'type': 'Resize',\n",
    "        'kwargs': {'size': [int(y/2) for y in x[1]['kwargs']['size']]}\n",
    "    }\n",
    "])\n",
    "df.to_pickle('../config/cholec80_retransforms.pkl')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Feature-based Homography Estimation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from kornia import warp_perspective, tensor_to_image\n",
    "\n",
    "from lightning_modules import DeepImageHomographyEstimationModuleBackbone\n",
    "from utils.processing import four_point_homography_to_matrix, image_edges\n",
    "from utils.processing import FeatureHomographyEstimation\n",
    "from utils.viz import yt_alpha_blend\n",
    "from utils.io import generate_path\n",
    "\n",
    "# feature-based model creationg stage\n",
    "fd = cv2.SIFT_create()\n",
    "fh = FeatureHomographyEstimation(fd)\n",
    "\n",
    "# deep creationg stage\n",
    "prefix = '/home/martin/Tresors/homography_imitation_learning_logs/deep_image_homography_estimation_backbone_search/version_8'\n",
    "configs = load_yaml(os.path.join(prefix, 'config.yml'))\n",
    "model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=99-step=44099.ckpt'), shape=configs['model']['shape'])\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print('Running with CUDA backend.')\n",
    "    device = 'cuda'\n",
    "\n",
    "model.to(device)\n",
    "model = model.eval()\n",
    "model.freeze()\n",
    "\n",
    "# log dataframe\n",
    "log_df = pd.DataFrame(columns=['frame_rate', 'video_fps', 'video_idx', 'idx', 'duv'])\n",
    "\n",
    "# data iterator\n",
    "test_dl = dm.test_dataloader()\n",
    "\n",
    "hist = []\n",
    "\n",
    "max_cnt = 3000\n",
    "cnt = 0\n",
    "\n",
    "for batch in tqdm(test_dl):\n",
    "    if cnt > max_cnt:\n",
    "        break\n",
    "    cnt += 1\n",
    "    # deep\n",
    "    batch = dm.transfer_batch_to_device(batch, device)\n",
    "    vid, aug_vid, frame_rate, video_fps, video_idx, idx = batch\n",
    "\n",
    "    img_deep, wrp_deep = vid[0,0].unsqueeze(0), vid[0,1].unsqueeze(0)\n",
    "\n",
    "    duv_deep = model(img_deep, wrp_deep)\n",
    "    duv_deep *= -1\n",
    "\n",
    "    uv_deep = image_edges(img_deep)\n",
    "    H_deep = four_point_homography_to_matrix(uv_deep, duv_deep)\n",
    "\n",
    "    # classical\n",
    "    batch = dm.transfer_batch_to_device(batch, 'cpu')\n",
    "    vid, aug_vid, frame_rate, video_fps, video_idx, idx = batch\n",
    "\n",
    "    img, wrp = tensor_to_image(vid[0,0]), tensor_to_image(vid[0,1])\n",
    "\n",
    "    H, duv = fh((img*255).astype(np.uint8), (wrp*255).astype(np.uint8))\n",
    "\n",
    "    if H is not None:\n",
    "        mpd = np.linalg.norm(duv - duv_deep.cpu().numpy().squeeze(), axis=1).mean()\n",
    "        log_df = log_df.append({\n",
    "            'frame_rate': frame_rate.numpy(), 'video_fps': np.array([x.numpy() for x in video_fps]), 'video_idx': video_idx.numpy(), 'idx': idx.numpy(), 'duv': duv, 'mpd': mpd\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        hist.append(mpd)\n",
    "        # # deep\n",
    "        # wrp_deep_reg = warp_perspective(img_deep, H_deep, (img_deep.shape[-2], img_deep.shape[-1]))\n",
    "\n",
    "        # blend_deep = yt_alpha_blend(wrp_deep, wrp_deep_reg)\n",
    "\n",
    "        # blend_deep = tensor_to_image(blend_deep)\n",
    "        # cv2.imshow('blend_deep', blend_deep)\n",
    "\n",
    "        # # classical\n",
    "        # wrp_reg = cv2.warpPerspective(img, H, (wrp.shape[1], wrp.shape[0]))\n",
    "\n",
    "        # blend = yt_alpha_blend(wrp, wrp_reg)\n",
    "\n",
    "        # cv2.imshow('blend', blend)\n",
    "        # cv2.waitKey()\n",
    "\n",
    "log_path = os.path.join(server.logging.location, 'homography_regression_discrepancy')\n",
    "generate_path(log_path)\n",
    "log_df.to_pickle(os.path.join(log_path, 'feature_based_frame_rate_{}.pkl'.format(frame_rate.item())))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/89715 [00:00<?, ?it/s]Running with CUDA backend.\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "  3%|â–Ž         | 3001/89715 [07:04<3:24:21,  7.07it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kornia import tensor_to_image\n",
    "\n",
    "log_path = os.path.join(server.logging.location, 'homography_regression_discrepancy')\n",
    "frame_rate = 5\n",
    "df = pd.read_pickle(os.path.join(log_path, 'feature_based_frame_rate_{}.pkl'.format(frame_rate)))\n",
    "\n",
    "ds = dm._test_set\n",
    "\n",
    "for _, row in df[df.mpd > 100].iterrows():\n",
    "    \n",
    "    batch = ds[row.idx.item()]\n",
    "    vid, aug_vid, frame_rate, video_fps, video_idx, idx = batch\n",
    "\n",
    "    img, wrp = tensor_to_image(vid[0]), tensor_to_image(vid[1])\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.imshow('wrp', wrp)\n",
    "    cv2.waitKey()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "\n",
    "# hist = np.array(hist)\n",
    "# print(hist.mean())\n",
    "# print(hist.std())\n",
    "\n",
    "# plt.hist(hist, bins=50)\n",
    "# plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Deep Homography Estimation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import cv2\n",
    "import torch\n",
    "from kornia import warp_perspective, tensor_to_image\n",
    "\n",
    "from lightning_modules import DeepImageHomographyEstimationModuleBackbone\n",
    "from utils.processing import four_point_homography_to_matrix, image_edges\n",
    "from utils.viz import yt_alpha_blend\n",
    "from utils.io import generate_path\n",
    "\n",
    "# model creationg stage\n",
    "prefix = '/home/martin/Tresors/homography_imitation_learning_logs/deep_image_homography_estimation_backbone_search/version_6'\n",
    "configs = load_yaml(os.path.join(prefix, 'config.yml'))\n",
    "model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=52-step=46692.ckpt'), shape=configs['model']['shape'])\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print('Running with CUDA backend.')\n",
    "    device = 'cuda'\n",
    "\n",
    "model.to(device)\n",
    "model = model.eval()\n",
    "model.freeze()\n",
    "\n",
    "# log dataframe\n",
    "log_df = pd.DataFrame(columns=['frame_rate', 'video_fps', 'video_idx', 'idx', 'duv'])\n",
    "\n",
    "# data iterator\n",
    "test_dl = dm.test_dataloader()\n",
    "\n",
    "for batch in test_dl:\n",
    "    batch = dm.transfer_batch_to_device(batch, device)\n",
    "    vid, aug_vid, frame_rate, video_fps, video_idx, idx = batch\n",
    "\n",
    "    img, wrp = vid[0,0].unsqueeze(0), vid[0,1].unsqueeze(0)\n",
    "\n",
    "    duv = model(img, wrp)\n",
    "    duv *= -1\n",
    "\n",
    "    log_df = log_df.append({\n",
    "        'frame_rate': frame_rate.cpu().numpy(), 'video_fps': np.array([x.cpu().numpy() for x in video_fps]), 'video_idx': video_idx.cpu().numpy(), 'idx': idx.cpu().numpy(), 'duv': duv.cpu().numpy()\n",
    "    }, ignore_index=True)\n",
    "\n",
    "    # uv = image_edges(img)\n",
    "    # H = four_point_homography_to_matrix(uv, duv)\n",
    "\n",
    "    # wrp_reg = warp_perspective(img, H, (img.shape[-2], img.shape[-1]))\n",
    "\n",
    "    # blend = yt_alpha_blend(wrp, wrp_reg)\n",
    "\n",
    "    # blend = tensor_to_image(blend)\n",
    "    # cv2.imshow('blend', blend)\n",
    "    # cv2.waitKey()\n",
    "\n",
    "log_path = os.path.join(server.logging.location, 'homography_regression_discrepancy')\n",
    "generate_path(log_path)\n",
    "log_df.to_pickle(os.path.join(log_path, 'deep_frame_rate_{}.pkl'.format(frame_rate.item())))\n",
    "\n",
    "# iterate through test set\n",
    "\n",
    "# estimate homography, store duv, idx -> mangage to load frame by index"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running with CUDA backend.\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/kornia/geometry/transform/imgwarp.py:98: UserWarning: The align_corners default value has been changed. By default now is set True in order to match cv2.warpPerspective. In case you want to keep your previous behaviour set it to False. This warning will disappear in kornia > v0.6.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "feature_df = pd.read_pickle('/media/martin/Samsung_T5/logs/homography_regression_discrepancy/feature_based_frame_rate_5.pkl')\n",
    "deep_df = pd.read_pickle('/media/martin/Samsung_T5/logs/homography_regression_discrepancy/deep_frame_rate_5.pkl')\n",
    "\n",
    "# diff = feature_df.duv - deep_df.duv\n",
    "\n",
    "# print(diff)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0      [[[-35.307350158691406, 25.879680633544922], [...\n",
      "1      [[[-25.74515390396118, 23.259612321853638], [-...\n",
      "2      [[[-34.93977928161621, 28.84478187561035], [-0...\n",
      "3      [[[-20.24051344394684, 21.259456872940063], [-...\n",
      "4      [[[-35.004459381103516, 36.209375500679016], [...\n",
      "                             ...                        \n",
      "295    [[[-5.1263673305511475, -6.074093461036682], [...\n",
      "296    [[[-10.244562864303589, -5.198544144630432], [...\n",
      "297    [[[-8.791977047920227, -5.269481897354126], [5...\n",
      "298    [[[-4.958159148693085, -5.206058144569397], [1...\n",
      "299    [[[-6.0587605237960815, -4.56786236166954], [-...\n",
      "Name: duv, Length: 300, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}