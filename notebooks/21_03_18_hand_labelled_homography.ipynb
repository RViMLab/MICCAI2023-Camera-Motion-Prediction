{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hand-labelled Homography\n",
    "Generate a pipeline for quantitative analysis of homography estimation. Do\n",
    " - Randomly sample sequences from list of videos\n",
    " - Safe sequences into folder\n",
    " - Annotate some sequences\n",
    " - Create evaluation pipeline, precision, drift\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from dotmap import DotMap\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.io import load_yaml\n",
    "\n",
    "server = 'local'\n",
    "servers = load_yaml('../config/servers.yml')\n",
    "server = DotMap(servers[server])\n",
    "\n",
    "meta_df = pd.read_pickle('../config/cholec80_transforms.pkl')\n",
    "meta_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    database train                                       file  \\\n",
       "0   cholec80  True  {'name': 'video01.mp4', 'path': 'videos'}   \n",
       "1   cholec80  True  {'name': 'video02.mp4', 'path': 'videos'}   \n",
       "2   cholec80  True  {'name': 'video03.mp4', 'path': 'videos'}   \n",
       "3   cholec80  True  {'name': 'video04.mp4', 'path': 'videos'}   \n",
       "4   cholec80  True  {'name': 'video05.mp4', 'path': 'videos'}   \n",
       "..       ...   ...                                        ...   \n",
       "70  cholec80  True  {'name': 'video17.mp4', 'path': 'videos'}   \n",
       "71  cholec80  True  {'name': 'video18.mp4', 'path': 'videos'}   \n",
       "72  cholec80  True  {'name': 'video19.mp4', 'path': 'videos'}   \n",
       "73  cholec80  True  {'name': 'video20.mp4', 'path': 'videos'}   \n",
       "74  cholec80  True  {'name': 'video22.mp4', 'path': 'videos'}   \n",
       "\n",
       "                                       pre_transforms  \\\n",
       "0   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "1   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "2   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "3   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "4   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "..                                                ...   \n",
       "70  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "71  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "72  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "73  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "74  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "\n",
       "                                       aug_transforms auxiliary  \n",
       "0   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "1   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "2   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "3   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "4   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "..                                                ...       ...  \n",
       "70  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "71  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "72  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "73  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "74  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "\n",
       "[75 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>train</th>\n",
       "      <th>file</th>\n",
       "      <th>pre_transforms</th>\n",
       "      <th>aug_transforms</th>\n",
       "      <th>auxiliary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video01.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video02.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video03.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video04.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video05.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video17.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video18.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video19.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video20.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>cholec80</td>\n",
       "      <td>True</td>\n",
       "      <td>{'name': 'video22.mp4', 'path': 'videos'}</td>\n",
       "      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n",
       "      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Randomly Sample Image Sequences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from kornia import tensor_to_image\n",
    "\n",
    "from utils.transforms import anyDictListToCompose\n",
    "from utils.sampling import RandomSequences\n",
    "from utils.io import generate_path\n",
    "\n",
    "debug = True\n",
    "\n",
    "max_seq = 10\n",
    "paths = meta_df.apply(lambda x: os.path.join(server.database.location, x.database, x.file['path'], x.file['name']), axis=1).tolist()\n",
    "seq_len = 20\n",
    "strides = [5]\n",
    "\n",
    "# append to tensor transform, as meta_df is supposed to operate on tensors\n",
    "to_tensor = {'module': 'torchvision.transforms', 'type': 'ToTensor', 'kwargs': {}}\n",
    "transforms = meta_df.apply(lambda x: anyDictListToCompose([to_tensor] + x.pre_transforms), axis=1).tolist()\n",
    "\n",
    "random_sequences = RandomSequences(\n",
    "    max_seq=max_seq,\n",
    "    paths=paths,\n",
    "    seq_len=seq_len,\n",
    "    strides=strides,\n",
    "    transforms=transforms,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "out_prefix = 'out/homography_labelling'\n",
    "\n",
    "for seq, vid_idx, frame_idx in random_sequences:\n",
    "    print('vid_idx: {}, frame_idx: {}'.format(vid_idx, frame_idx))\n",
    "    for idx, frame in enumerate(seq):\n",
    "        frame = (tensor_to_image(frame)*255).astype(np.uint8)\n",
    "        if debug:\n",
    "            cv2.imshow('random_frame', frame)  # show images\n",
    "            cv2.waitKey()\n",
    "        else:\n",
    "            vid_path = os.path.join(out_prefix, 'vid_{}_frame_{}'.format(vid_idx, frame_idx))\n",
    "            generate_path(vid_path)\n",
    "            cv2.imwrite(os.path.join(vid_path, 'frame_{}.png'.format(frame_idx + idx*strides[0])), frame)\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset on Sampled Frames"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import os\n",
    "\n",
    "from utils.io import recursive_scan2df\n",
    "\n",
    "prefix = 'out/homography_labelling'\n",
    "\n",
    "# create a simplified dataframe\n",
    "postfix = '.png'\n",
    "df = recursive_scan2df(prefix, postfix)\n",
    "df['vid'] = df.folder.apply(lambda x: int(x.split('_')[1]))\n",
    "df['frame'] = df.file.apply(lambda x: int(x.split('_')[-1].replace(postfix, '')))\n",
    "df = df.sort_values(['vid', 'frame']).reset_index(drop=True)\n",
    "\n",
    "out_path = 'light_log'\n",
    "df.to_pickle(os.path.join(prefix, out_path + '.pkl'))\n",
    "\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                file              folder  vid  frame\n",
       "0     frame_5980.png    vid_0_frame_5980    0   5980\n",
       "1     frame_5985.png    vid_0_frame_5980    0   5985\n",
       "2     frame_5990.png    vid_0_frame_5980    0   5990\n",
       "3     frame_5995.png    vid_0_frame_5980    0   5995\n",
       "4     frame_6000.png    vid_0_frame_5980    0   6000\n",
       "..               ...                 ...  ...    ...\n",
       "335  frame_11041.png  vid_60_frame_10966   60  11041\n",
       "336  frame_11046.png  vid_60_frame_10966   60  11046\n",
       "337  frame_11051.png  vid_60_frame_10966   60  11051\n",
       "338  frame_11056.png  vid_60_frame_10966   60  11056\n",
       "339  frame_11061.png  vid_60_frame_10966   60  11061\n",
       "\n",
       "[340 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>folder</th>\n",
       "      <th>vid</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame_5980.png</td>\n",
       "      <td>vid_0_frame_5980</td>\n",
       "      <td>0</td>\n",
       "      <td>5980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame_5985.png</td>\n",
       "      <td>vid_0_frame_5980</td>\n",
       "      <td>0</td>\n",
       "      <td>5985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame_5990.png</td>\n",
       "      <td>vid_0_frame_5980</td>\n",
       "      <td>0</td>\n",
       "      <td>5990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame_5995.png</td>\n",
       "      <td>vid_0_frame_5980</td>\n",
       "      <td>0</td>\n",
       "      <td>5995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame_6000.png</td>\n",
       "      <td>vid_0_frame_5980</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>frame_11041.png</td>\n",
       "      <td>vid_60_frame_10966</td>\n",
       "      <td>60</td>\n",
       "      <td>11041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>frame_11046.png</td>\n",
       "      <td>vid_60_frame_10966</td>\n",
       "      <td>60</td>\n",
       "      <td>11046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>frame_11051.png</td>\n",
       "      <td>vid_60_frame_10966</td>\n",
       "      <td>60</td>\n",
       "      <td>11051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>frame_11056.png</td>\n",
       "      <td>vid_60_frame_10966</td>\n",
       "      <td>60</td>\n",
       "      <td>11056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>frame_11061.png</td>\n",
       "      <td>vid_60_frame_10966</td>\n",
       "      <td>60</td>\n",
       "      <td>11061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Estimate Homographies on Sequences\n",
    "## Hand Labelled\n",
    "### Tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.io import recursive_scan2df\n",
    "from utils.viz import yt_alpha_blend\n",
    "\n",
    "def image_edges(shape):\n",
    "    uv = np.array([\n",
    "            [0           , 0           ],\n",
    "            [0           , shape[1] - 1],\n",
    "            [shape[0] - 1, shape[1] - 1],\n",
    "            [shape[0] - 1, 0           ],\n",
    "    ], dtype=np.float)\n",
    "    return uv\n",
    "\n",
    "\n",
    "prefix = 'out/homography_labelling'\n",
    "vid_df = pd.read_pickle(os.path.join(prefix, 'light_log.pkl'))\n",
    "pts_df = recursive_scan2df(prefix, '.txt')\n",
    "mpds = []\n",
    "\n",
    "for _, row in pts_df.iterrows():\n",
    "    df = pd.read_csv(os.path.join(prefix, row.folder, row.file), delimiter='\\t', header=None, names=['x', 'y']) # stored as x, y opencv convention\n",
    "    n_img = len(vid_df[vid_df.folder == row.folder])\n",
    "    n_pts = int(len(df) / n_img)\n",
    "\n",
    "    print('N Points: {}'.format(n_pts))\n",
    "    print(row.folder, row.file)\n",
    "    \n",
    "    # get homography\n",
    "    for img_idx in range(n_img - 1):\n",
    "        src_pts = df.iloc[img_idx*n_pts:(img_idx+1)*n_pts]\n",
    "        dst_pts = df.iloc[(img_idx+1)*n_pts:(img_idx+2)*n_pts]\n",
    "        \n",
    "        src_pts = np.array([[pt.x, pt.y] for _, pt in src_pts.iterrows()])\n",
    "        dst_pts = np.array([[pt.x, pt.y] for _, pt in dst_pts.iterrows()])\n",
    "\n",
    "        H, _ = cv2.findHomography(src_pts, dst_pts)\n",
    "        \n",
    "        # show images\n",
    "        img = cv2.imread(os.path.join(prefix, vid_df[vid_df.folder == row.folder].iloc[img_idx].folder, vid_df[vid_df.folder == row.folder].iloc[img_idx].file))\n",
    "        wrp = cv2.imread(os.path.join(prefix, vid_df[vid_df.folder == row.folder].iloc[img_idx + 1].folder, vid_df[vid_df.folder == row.folder].iloc[img_idx + 1].file))\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.imshow('wrp', wrp)\n",
    "\n",
    "        # create blend\n",
    "        wrp_pred = cv2.warpPerspective(img, H, (img.shape[1], img.shape[0]))\n",
    "        cv2.imshow('wrp_pred', wrp_pred)\n",
    "        blend = yt_alpha_blend(wrp, wrp_pred)\n",
    "        cv2.imshow('blend', blend/255)  # note that more points are needed, or blend will only work locally around pts\n",
    "        cv2.waitKey()\n",
    "\n",
    "        # duv analysis\n",
    "        resize_shape = [240, 320]\n",
    "        shape = img.shape\n",
    "\n",
    "        scale = np.array([resize_shape[-2]/shape[0], resize_shape[-1]/shape[1]])\n",
    "\n",
    "        src_pts *= scale\n",
    "        dst_pts *= scale\n",
    "\n",
    "        H, _ = cv2.findHomography(src_pts, dst_pts)\n",
    "\n",
    "        edges = image_edges(resize_shape)\n",
    "        edges = np.array(edges)\n",
    "        wrp_edges = cv2.perspectiveTransform(edges.reshape(-1,1,2)[:,:,::-1], H)[:,:,::-1].squeeze()\n",
    "        mpd = np.linalg.norm(edges - wrp_edges, axis=1).mean()\n",
    "        mpds.append(mpd)\n",
    "\n",
    "plt.hist(mpds)\n",
    "plt.show()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N Points: 7\n",
      "vid_19_frame_0 sample_idx_66.txt\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N Points: 7\n",
      "vid_18_frame_0 sample_idx_65.txt\n",
      "N Points: 7\n",
      "vid_16_frame_0 sample_idx_56.txt\n",
      "N Points: 7\n",
      "vid_0_frame_5980 pts.txt\n",
      "N Points: 7\n",
      "vid_15_frame_0 sample_idx_2.txt\n",
      "N Points: 8\n",
      "vid_6_frame_0 sample_idx_6.txt\n",
      "N Points: 6\n",
      "vid_12_frame_0 sample_idx_45.txt\n",
      "N Points: 7\n",
      "vid_13_frame_0 sample_idx_47.txt\n",
      "N Points: 6\n",
      "vid_5_frame_0 sample_idx_4.txt\n",
      "N Points: 7\n",
      "vid_11_frame_0 sample_idx_40.txt\n",
      "N Points: 6\n",
      "vid_4_frame_0 sample_idx_4.txt\n",
      "N Points: 6\n",
      "vid_36_frame_14944 pts.txt\n",
      "N Points: 6\n",
      "vid_8_frame_0 sample_idx_22.txt\n",
      "N Points: 7\n",
      "vid_1_frame_0 sample_idx_2.txt\n",
      "N Points: 7\n",
      "vid_17_frame_0 sample_idx_64.txt\n",
      "N Points: 6\n",
      "vid_14_frame_0 sample_idx_53.txt\n",
      "N Points: 8\n",
      "vid_58_frame_10791 pts.txt\n",
      "N Points: 8\n",
      "vid_7_frame_0 sample_idx_6.txt\n",
      "N Points: 6\n",
      "vid_10_frame_0 sample_idx_37.txt\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mean-Pairwise-Distance Error on Hand-labelled Points"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from kornia import tensor_to_image, image_to_tensor, warp_perspective\n",
    "from torch.utils.data import DataLoader\n",
    "from dotmap import DotMap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from datasets import ImageSequenceDataset\n",
    "from utils.transforms import anyDictListToCompose\n",
    "from utils.processing import FeatureHomographyEstimation, four_point_homography_to_matrix, image_edges\n",
    "from utils.io import load_yaml, recursive_scan2df, generate_path\n",
    "from utils.viz import yt_alpha_blend, draw_points\n",
    "from lightning_modules import DeepImageHomographyEstimationModuleBackbone\n",
    "\n",
    "server = 'local'\n",
    "servers = load_yaml('../config/servers.yml')\n",
    "server = DotMap(servers[server])\n",
    "\n",
    "meta_df = pd.read_pickle('../config/cholec80_transforms.pkl')\n",
    "\n",
    "show_image = True\n",
    "save_figure = False\n",
    "save_pdf = False\n",
    "save_png = False\n",
    "figure_prefix = 'out/homography_labelling/fig'\n",
    "generate_path(figure_prefix)\n",
    "\n",
    "# classical esimation\n",
    "with_feature_estimation = False\n",
    "fd = cv2.xfeatures2d.SURF_create()\n",
    "# fd = cv2.ORB_create()\n",
    "fh = FeatureHomographyEstimation(fd)\n",
    "\n",
    "# deep estimation\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/ae_cai/resnet/34/version_0' #!!!!!!!!!\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/ae_cai/resnet/50/version_0' #!!!!!!!!\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/ae_cai/resnet/50/version_0'\n",
    "prefix = '/home/martin/Tresors/homography_imitation_learning_logs/ae_cai/resnet/48/25/34/version_0'\n",
    "\n",
    "configs = load_yaml(os.path.join(prefix, 'config.yml'))\n",
    "\n",
    "# model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=49-step=94349.ckpt'), shape=configs['model']['shape']) #!!!!!!!!!!!!!\n",
    "model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=99-step=47199.ckpt'), shape=configs['model']['shape'])\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print('Running with CUDA backend.')\n",
    "    device = 'cuda'\n",
    "# device = 'cpu' # for analysis\n",
    "\n",
    "model.to(device)\n",
    "model = model.eval()\n",
    "model.freeze()\n",
    "\n",
    "prefix = 'out/homography_labelling'\n",
    "vid_df = pd.read_pickle(os.path.join(prefix, 'light_log.pkl'))\n",
    "pts_df = recursive_scan2df(prefix, '.txt')\n",
    "\n",
    "float_transform = torchvision.transforms.ConvertImageDtype(torch.float)\n",
    "\n",
    "# errors\n",
    "lobd_mpd = []  # to show how well transformation can be described via homography (lower bound)\n",
    "none_mpd = []\n",
    "deep_mpd = []\n",
    "ft_mpd = []\n",
    "deep_dt = []\n",
    "ft_dt = []\n",
    "\n",
    "lobd_df = pd.DataFrame(columns=['duv', 'duv_mpd'])\n",
    "none_df = pd.DataFrame(columns=['duv', 'duv_mpd'])\n",
    "deep_df = pd.DataFrame(columns=['duv', 'duv_mpd'])\n",
    "ft_df = pd.DataFrame(columns=['duv', 'duv_mpd'])\n",
    "\n",
    "for row_idx, row in pts_df.iterrows():\n",
    "    df = pd.read_csv(os.path.join(prefix, row.folder, row.file), delimiter='\\t', header=None, names=['x', 'y']) # stored as x, y opencv convention\n",
    "    n_img = len(vid_df[vid_df.folder == row.folder])\n",
    "    n_pts = int(len(df) / n_img)\n",
    "\n",
    "    print('N Points: {}'.format(n_pts))\n",
    "    \n",
    "    # get homography\n",
    "    for img_idx in range(n_img - 1):\n",
    "        # load images\n",
    "        img = cv2.imread(os.path.join(prefix, vid_df[vid_df.folder == row.folder].iloc[img_idx].folder, vid_df[vid_df.folder == row.folder].iloc[img_idx].file))\n",
    "        wrp = cv2.imread(os.path.join(prefix, vid_df[vid_df.folder == row.folder].iloc[img_idx + 1].folder, vid_df[vid_df.folder == row.folder].iloc[img_idx + 1].file))\n",
    "\n",
    "        resize_shape = configs['model']['shape']\n",
    "        shape = img.shape\n",
    "\n",
    "        scale = np.array([resize_shape[-2]/shape[0], resize_shape[-1]/shape[1]])\n",
    "\n",
    "        src_pts = df.iloc[img_idx*n_pts:(img_idx+1)*n_pts]\n",
    "        dst_pts = df.iloc[(img_idx+1)*n_pts:(img_idx+2)*n_pts]\n",
    "        \n",
    "        src_pts = np.array([[pt.x, pt.y] for _, pt in src_pts.iterrows()])\n",
    "        dst_pts = np.array([[pt.x, pt.y] for _, pt in dst_pts.iterrows()])\n",
    "\n",
    "        src_pts *= scale\n",
    "        dst_pts *= scale\n",
    "\n",
    "        H_lobd, _ = cv2.findHomography(src_pts, dst_pts)\n",
    "\n",
    "        img, wrp = cv2.resize(img, (resize_shape[-1], resize_shape[-2])), cv2.resize(wrp, (resize_shape[-1], resize_shape[-2]))\n",
    "\n",
    "        # configs['model']['shape']\n",
    "\n",
    "        img, wrp = float_transform(image_to_tensor(img, keepdim=False)).to(device), float_transform(image_to_tensor(wrp, keepdim=False)).to(device)\n",
    "\n",
    "        deep_start = time.time()\n",
    "        duv = model(img, wrp)\n",
    "        deep_dt.append(time.time() - deep_start)\n",
    "\n",
    "        # deep prediction\n",
    "        uv = image_edges(img)\n",
    "        H_deep = four_point_homography_to_matrix(uv, duv)  # H: dst -> src\n",
    "        H_deep_inv = torch.inverse(H_deep)\n",
    "        H_deep_inv = H_deep_inv.cpu().numpy()\n",
    "\n",
    "        # feature prediction\n",
    "        img, wrp = (tensor_to_image(img)*255).astype(np.uint8), (tensor_to_image(wrp)*255).astype(np.uint8)\n",
    "        ft_start = time.time()\n",
    "        H_ft, duv_ft = fh(img, wrp)\n",
    "        ft_dt.append(time.time() - ft_start)\n",
    "\n",
    "        if H_ft is None:\n",
    "            print('Skipping')\n",
    "            continue\n",
    "\n",
    "        dst_pts_deep = cv2.perspectiveTransform(src_pts.reshape(-1, 1, 2), H_deep_inv[0]).reshape(-1, 2)\n",
    "        dst_pts_ft   = cv2.perspectiveTransform(src_pts.reshape(-1, 1, 2), H_ft).reshape(-1, 2)\n",
    "        dst_pts_lobd = cv2.perspectiveTransform(src_pts.reshape(-1, 1, 2), H_lobd).reshape(-1, 2)\n",
    "\n",
    "        dst_col = (255, 255, 0)\n",
    "        dst_deep_col = (255, 0, 255)\n",
    "        dst_ft_col = (0, 255, 255)\n",
    "\n",
    "        wrp = draw_points(wrp, dst_pts, rad=3, col=dst_col)      # dst\n",
    "        # wrp = draw_points(wrp, src_pts, rad=3, col=(0, 255, 255))     # src\n",
    "        wrp = draw_points(wrp, dst_pts_deep, rad=3, col=dst_deep_col) # dst prediction deep\n",
    "        wrp = draw_points(wrp, dst_pts_ft, rad=3, col=dst_ft_col)   # dst prediction feature\n",
    "\n",
    "        # compute distance\n",
    "        lobd_mpd.append(np.linalg.norm(dst_pts - dst_pts_lobd, axis=1).mean())\n",
    "        none_mpd.append(np.linalg.norm(dst_pts - src_pts, axis=1).mean())\n",
    "        deep_mpd.append(np.linalg.norm(dst_pts - dst_pts_deep, axis=1).mean())\n",
    "        ft_mpd.append(np.linalg.norm(dst_pts - dst_pts_ft, axis=1).mean())\n",
    "\n",
    "        # safe raw deviation\n",
    "        lobd_df = lobd_df.append({'duv': dst_pts - dst_pts_lobd, 'duv_mpd': lobd_mpd[-1]}, ignore_index=True)\n",
    "        none_df = none_df.append({'duv': dst_pts - src_pts, 'duv_mpd': none_mpd[-1]}, ignore_index=True)\n",
    "        deep_df = deep_df.append({'duv': dst_pts - dst_pts_deep, 'duv_mpd': deep_mpd[-1]}, ignore_index=True)\n",
    "        ft_df   = ft_df.append({'duv': dst_pts - dst_pts_ft, 'duv_mpd': ft_mpd[-1]}, ignore_index=True)\n",
    "\n",
    "        if save_figure:\n",
    "            figure = plt.figure()\n",
    "            ax = figure.add_subplot(111)\n",
    "\n",
    "            dst_patch = mpatches.Patch(color=tuple(ti/255 for ti in dst_col), label='Destination')\n",
    "            dst_deep_patch = mpatches.Patch(color=tuple(ti/255 for ti in dst_deep_col), label='Deep')\n",
    "            dst_ft_patch = mpatches.Patch(color=tuple(ti/255 for ti in dst_ft_col), label='Feature-based')\n",
    "            ax.legend(handles=[dst_patch, dst_deep_patch, dst_ft_patch])\n",
    "            plt.imshow(wrp[...,::-1])\n",
    "            \n",
    "            if save_pdf:\n",
    "                plt.savefig(os.path.join(figure_prefix, 'labelled_dots_{}_{}.pdf'.format(row_idx, img_idx)))\n",
    "            if save_png:\n",
    "                plt.savefig(os.path.join(figure_prefix, 'labelled_dots_{}_{}.png'.format(row_idx, img_idx)), dpi=300)\n",
    "        elif show_image: \n",
    "            cv2.putText(wrp, 'Desired', (10, 20), cv2.FONT_HERSHEY_PLAIN, 1.0, dst_col, 2)\n",
    "            cv2.putText(wrp, 'Deep', (10, 40), cv2.FONT_HERSHEY_PLAIN, 1.0, dst_deep_col, 2)\n",
    "            cv2.putText(wrp, 'Feature-based', (10, 60), cv2.FONT_HERSHEY_PLAIN, 1.0, dst_ft_col, 2)\n",
    "            cv2.imshow('wrp', wrp)\n",
    "            cv2.waitKey()\n",
    "\n",
    "lobd_mpd = np.array(lobd_mpd)\n",
    "none_mpd = np.array(none_mpd)\n",
    "deep_mpd = np.array(deep_mpd)\n",
    "ft_mpd = np.array(ft_mpd)\n",
    "deep_dt = np.array(deep_dt)\n",
    "ft_dt = np.array(ft_dt)\n",
    "\n",
    "none_mpd_mean, none_mpd_std = none_mpd.mean(), none_mpd.std()\n",
    "lobd_mpd_mean, lobd_mpd_std = lobd_mpd.mean(), lobd_mpd.std()\n",
    "deep_mpd_mean, deep_mpd_std = deep_mpd.mean(), deep_mpd.std()\n",
    "ft_mpd_mean, ft_mpd_std = ft_mpd.mean(), ft_mpd.std()\n",
    "deep_dt_mean, deep_dt_std = deep_dt.mean(), deep_dt.std()\n",
    "ft_dt_mean, ft_dt_std = ft_dt.mean(), ft_dt.std()\n",
    "\n",
    "print('none: {:.2f} +/- {:.2f}'.format(none_mpd.mean(), none_mpd.std()))\n",
    "print('lobd: {:.2f} +/- {:.2f}'.format(lobd_mpd.mean(), lobd_mpd.std()))\n",
    "print('deep: {:.2f} +/- {:.2f}'.format(deep_mpd.mean(), deep_mpd.std()))\n",
    "print('ft:   {:.2f} +/- {:.2f}'.format(ft_mpd.mean(), ft_mpd.std()))\n",
    "print('deep_dt:   {:.2f} +/- {:.2f}'.format(deep_dt_mean*1.e3, deep_dt_std*1.e3))\n",
    "print('ft_dt:   {:.2f} +/- {:.2f}'.format(ft_dt_mean*1.e3, ft_dt_std*1.e3))\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running with CUDA backend.\n",
      "N Points: 7\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-23d8e418895a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# load images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mwrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mresize_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hil/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hil/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hil/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.io import generate_path\n",
    "\n",
    "labels = [\n",
    "    'None',\n",
    "    'Lower bound',\n",
    "    'Deep: Resnet34',\n",
    "    'Feature-based: SIFT'\n",
    "]\n",
    "\n",
    "means = [\n",
    "    none_mpd_mean,\n",
    "    lobd_mpd_mean,\n",
    "    deep_mpd_mean,\n",
    "    ft_mpd_mean\n",
    "]\n",
    "\n",
    "stds = [\n",
    "    none_mpd_std,\n",
    "    lobd_mpd_std,\n",
    "    deep_mpd_std,\n",
    "    ft_mpd_std\n",
    "]\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    plt.errorbar(idx, means[idx], yerr=stds[idx], label=r'{} {:.2f}$\\pm${:.2f} pixel'.format(label, means[idx], stds[idx]), fmt='o')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Hand-labelled Marker Error')\n",
    "plt.ylabel('Mean Pairwise Distance / pixel')\n",
    "plt.grid()\n",
    "# plt.show()\n",
    "prefix = 'out/homography_labelling/fig'\n",
    "generate_path(prefix)\n",
    "plt.savefig(os.path.join(prefix, 'hand_labelled_mean_pairwise_distance.pdf'))\n",
    "plt.savefig(os.path.join(prefix, 'hand_labelled_mean_pairwise_distance.png'), dpi=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# duv_dfs = [lobd_df, none_df, deep_df, ft_df]\n",
    "duv_dfs = [none_df, deep_df, ft_df]\n",
    "# labels = ['lobd', 'none', 'deep', 'ft']\n",
    "labels = ['Identity', 'ResNet-34', 'SURF & RANSAC']\n",
    "\n",
    "for duv_df, label in zip(duv_dfs, labels):\n",
    "\n",
    "    duv_df['duv_mpd'] = duv_df.duv.apply(lambda x: np.linalg.norm(x, axis=1).mean())\n",
    "\n",
    "    stats_df = duv_df.groupby('duv_mpd')['duv_mpd'].agg('count').pipe(pd.DataFrame).rename(columns = {'duv_mpd': 'frequency'})\n",
    "\n",
    "    # PDF\n",
    "    stats_df['pdf'] = stats_df['frequency'] / sum(stats_df['frequency'])\n",
    "\n",
    "    # CDF\n",
    "    stats_df['cdf'] = stats_df['pdf'].cumsum()\n",
    "    stats_df = stats_df.reset_index()\n",
    "\n",
    "    th30 = stats_df[stats_df.cdf < 0.3].iloc[-1]\n",
    "    th50 = stats_df[stats_df.cdf < 0.5].iloc[-1]\n",
    "    th70 = stats_df[stats_df.cdf < 0.7].iloc[-1]\n",
    "    th90 = stats_df[stats_df.cdf < 0.9].iloc[-1]\n",
    "\n",
    "    print('{} - {:.2f}/{:.2f}/{:.2f}/{:.2f}'.format(label, th30.duv_mpd, th50.duv_mpd, th70.duv_mpd, th90.duv_mpd))\n",
    "\n",
    "    # for stats_df, fd in zip(stats_dfs, fds):\n",
    "\n",
    "    plt.plot(stats_df['duv_mpd'], stats_df['cdf'], label=label)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlim([0, 15])\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('/media/martin/Samsung_T5/03_07_21_ae_cai_measurements/fig/frac/resnet34_48_25.pdf')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Identity - 2.36/3.44/4.33/7.60\n",
      "ResNet-34 - 1.00/1.26/1.59/2.15\n",
      "SURF & RANSAC - 1.09/1.48/2.07/3.53\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for duv_df, label in zip(duv_dfs, labels):\n",
    "    duv_df.to_pickle('/media/martin/Samsung_T5/03_07_21_ae_cai_measurements/data/frac/{}.pkl'.format(label))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Forward-Backward Consistency"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.functional as F\n",
    "from kornia import tensor_to_image, warp_perspective\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "from dotmap import DotMap\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.viz import yt_alpha_blend\n",
    "from utils.transforms import anyDictListToCompose\n",
    "from utils.processing import forward_backward_sequence, image_edges, four_point_homography_to_matrix\n",
    "from utils.io import load_yaml\n",
    "from datasets import ImageSequenceDataset\n",
    "from lightning_modules import DeepImageHomographyEstimationModuleBackbone\n",
    "\n",
    "server = 'local'\n",
    "servers = load_yaml('../config/servers.yml')\n",
    "server = DotMap(servers[server])\n",
    "\n",
    "meta_df = pd.read_pickle('../config/cholec80_transforms.pkl')\n",
    "\n",
    "\n",
    "def visualize(fw_img, fw_wrp, bw_img, bw_wrp, fw_duv, bw_duv):\n",
    "    fw_uv, bw_uv = image_edges(fw_img), image_edges(bw_img)\n",
    "    fw_H, bw_H = four_point_homography_to_matrix(fw_uv, fw_duv), four_point_homography_to_matrix(bw_uv, bw_duv)\n",
    "\n",
    "    fw_pred_wrp = warp_perspective(fw_img, torch.inverse(fw_H), fw_img.shape[-2:])\n",
    "    bw_pred_wrp = warp_perspective(bw_img, torch.inverse(bw_H), bw_img.shape[-2:])\n",
    "    \n",
    "    fw_blend, bw_blend = yt_alpha_blend(fw_wrp, fw_pred_wrp), yt_alpha_blend(bw_wrp, bw_pred_wrp)\n",
    "    fw_blend, bw_blend = tensor_to_image(fw_blend), tensor_to_image(bw_blend)\n",
    "\n",
    "    cv2.imshow('fw_blend', fw_blend)\n",
    "    cv2.imshow('bw_blend', bw_blend)\n",
    "    cv2.waitKey()\n",
    "\n",
    "prefix = 'out/homography_labelling'\n",
    "# prefix = '/media/martin/Samsung_T5/data/endoscopic_data/camera_motion_separated_npy/without_camera_motion'\n",
    "df = pd.read_pickle(os.path.join(prefix, 'light_log.pkl'))\n",
    "# df = pd.read_pickle(os.path.join(prefix, 'light_log_without_camera_motion.pkl'))\n",
    "seq_len = 2\n",
    "\n",
    "transforms = [\n",
    "    {'module': 'torchvision.transforms', 'type': 'ConvertImageDtype', 'kwargs': {'dtype': torch.float}}\n",
    "]\n",
    "transforms = [anyDictListToCompose(transforms) for _ in range(len(meta_df))]\n",
    "\n",
    "ds = ImageSequenceDataset(\n",
    "    df=df,\n",
    "    prefix=prefix,\n",
    "    seq_len=seq_len,\n",
    "    transforms=transforms\n",
    ")\n",
    "\n",
    "# load network\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/deep_image_homography_estimation_backbone/version_2'\n",
    "prefix = '/home/martin/Tresors/homography_imitation_learning_logs/deep_image_homography_estimation_backbone/version_10'\n",
    "configs = load_yaml(os.path.join(prefix, 'config.yml'))\n",
    "# model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=49.ckpt'), shape=configs['model']['shape'])\n",
    "model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=53-step=47573.ckpt'), shape=configs['model']['shape'])\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print('Running with CUDA backend.')\n",
    "    device = 'cuda'\n",
    "\n",
    "model.to(device)\n",
    "model = model.eval()\n",
    "model.freeze()\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 0\n",
    "\n",
    "dl = DataLoader(ds, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "fw_mean_distance = []\n",
    "bw_mean_distance = []\n",
    "con_mean_distance = []\n",
    "\n",
    "I = 100\n",
    "for idx, batch in enumerate(dl):\n",
    "    fw, bw = forward_backward_sequence(batch)\n",
    "\n",
    "    # create pairs\n",
    "    fw_img, fw_wrp = fw[:,:-1:].view((-1,) + fw.shape[-3:]).to(device), fw[:,1::].view((-1,) + fw.shape[-3:]).to(device) \n",
    "    bw_img, bw_wrp = bw[:,:-1:].view((-1,) + bw.shape[-3:]).to(device), bw[:,1::].view((-1,) + bw.shape[-3:]).to(device)\n",
    "\n",
    "    # fw_img, fw_wrp, bw_img, bw_wrp = tensor_to_image(fw_img[0]), tensor_to_image(fw_wrp[0]), tensor_to_image(bw_img[0]), tensor_to_image(bw_wrp[0])\n",
    "    # cv2.imshow('fw_img', fw_img)\n",
    "    # cv2.imshow('fw_wrp', fw_wrp)\n",
    "    # cv2.imshow('bw_img', bw_img)\n",
    "    # cv2.imshow('bw_wrp', bw_wrp)\n",
    "    # cv2.waitKey()\n",
    "\n",
    "    fw_duv = model(fw_img, fw_wrp)\n",
    "    bw_duv = model(bw_img, bw_wrp)\n",
    "\n",
    "    # compute error, sum isnt that great of a measurement as 2*N vs N elements\n",
    "    fw_mean_distance.append(torch.linalg.norm(fw_duv.sum(axis=0), axis=1).mean().item())\n",
    "    bw_mean_distance.append(torch.linalg.norm(bw_duv.sum(axis=0), axis=1).mean().item())\n",
    "    duv = torch.cat((fw_duv, bw_duv))\n",
    "    con_mean_distance.append(torch.linalg.norm(duv.sum(axis=0), axis=1).mean().item())\n",
    "\n",
    "    if idx == I - 1:\n",
    "        break\n",
    "\n",
    "    visualize(fw_img, fw_wrp, bw_img, bw_wrp, fw_duv, bw_duv)\n",
    "\n",
    "fw_mean_distance = np.array(fw_mean_distance)\n",
    "bw_mean_distance = np.array(bw_mean_distance)\n",
    "con_mean_distance = np.array(con_mean_distance)\n",
    "\n",
    "print(fw_mean_distance.mean(), fw_mean_distance.var())\n",
    "print(bw_mean_distance.mean(), bw_mean_distance.var())\n",
    "print(con_mean_distance.mean(), con_mean_distance.var())\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efe34164bbb50e70fce224383f42acab6a26dd9dc9fafc86c4e503220a8c76a1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('hil': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "efe34164bbb50e70fce224383f42acab6a26dd9dc9fafc86c4e503220a8c76a1"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}