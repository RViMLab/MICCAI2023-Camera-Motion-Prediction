{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Hand Labelled Homography\n",
    "Generate a pipeline for quantitative analysis of homography estimation. Do\n",
    " - Randomly sample sequences from list of videos\n",
    " - Safe sequences into folder\n",
    " - Annotate some sequences\n",
    " - Create evaluation pipeline, precision, drift\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    database train                                       file  \\\n",
       "0   cholec80  True  {'name': 'video01.mp4', 'path': 'videos'}   \n",
       "1   cholec80  True  {'name': 'video02.mp4', 'path': 'videos'}   \n",
       "2   cholec80  True  {'name': 'video03.mp4', 'path': 'videos'}   \n",
       "3   cholec80  True  {'name': 'video04.mp4', 'path': 'videos'}   \n",
       "4   cholec80  True  {'name': 'video05.mp4', 'path': 'videos'}   \n",
       "..       ...   ...                                        ...   \n",
       "70  cholec80  True  {'name': 'video17.mp4', 'path': 'videos'}   \n",
       "71  cholec80  True  {'name': 'video18.mp4', 'path': 'videos'}   \n",
       "72  cholec80  True  {'name': 'video19.mp4', 'path': 'videos'}   \n",
       "73  cholec80  True  {'name': 'video20.mp4', 'path': 'videos'}   \n",
       "74  cholec80  True  {'name': 'video22.mp4', 'path': 'videos'}   \n",
       "\n",
       "                                       pre_transforms  \\\n",
       "0   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "1   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "2   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "3   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "4   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "..                                                ...   \n",
       "70  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "71  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "72  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "73  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "74  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "\n",
       "                                       aug_transforms auxiliary  \n",
       "0   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "1   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "2   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "3   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "4   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "..                                                ...       ...  \n",
       "70  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "71  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "72  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "73  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "74  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "\n",
       "[75 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>database</th>\n      <th>train</th>\n      <th>file</th>\n      <th>pre_transforms</th>\n      <th>aug_transforms</th>\n      <th>auxiliary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video01.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video02.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video03.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video04.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video05.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video17.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video18.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video19.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video20.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video22.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from dotmap import DotMap\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.io import load_yaml\n",
    "\n",
    "server = 'local'\n",
    "servers = load_yaml('../config/servers.yml')\n",
    "server = DotMap(servers[server])\n",
    "\n",
    "meta_df = pd.read_pickle('../config/cholec80_transforms.pkl')\n",
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vid_idx: 23, frame_idx: 18978\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from kornia import tensor_to_image\n",
    "\n",
    "from utils.transforms import anyDictListToCompose\n",
    "from utils.sampling import RandomSequences\n",
    "from utils.io import generate_path\n",
    "\n",
    "debug = False\n",
    "\n",
    "max_seq = 5\n",
    "paths = meta_df.apply(lambda x: os.path.join(server.database.location, x.database, x.file['path'], x.file['name']), axis=1).tolist()\n",
    "seq_len = 50\n",
    "strides = [1]\n",
    "\n",
    "# append to tensor transform, as meta_df is supposed to operate on tensors\n",
    "to_tensor = {'module': 'torchvision.transforms', 'type': 'ToTensor', 'kwargs': {}}\n",
    "transforms = meta_df.apply(lambda x: anyDictListToCompose([to_tensor] + x.pre_transforms), axis=1).tolist()\n",
    "\n",
    "random_sequences = RandomSequences(\n",
    "    max_seq=max_seq,\n",
    "    paths=paths,\n",
    "    seq_len=seq_len,\n",
    "    transforms=transforms,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "out_prefix = 'out/homography_labelling'\n",
    "\n",
    "for seq, vid_idx, frame_idx in random_sequences:\n",
    "    print('vid_idx: {}, frame_idx: {}'.format(vid_idx, frame_idx))\n",
    "    for idx, frame in enumerate(seq):\n",
    "        frame = (tensor_to_image(frame)*255).astype(np.uint8)\n",
    "        if debug:\n",
    "            cv2.imshow('random_frame', frame)  # show images\n",
    "            cv2.waitKey()\n",
    "        else:\n",
    "            vid_path = os.path.join(out_prefix, 'vid_{}'.format(vid_idx))\n",
    "            generate_path(vid_path)\n",
    "            cv2.imwrite(os.path.join(vid_path, 'frame_{}.png'.format(frame_idx + idx*strides[0])), frame)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}