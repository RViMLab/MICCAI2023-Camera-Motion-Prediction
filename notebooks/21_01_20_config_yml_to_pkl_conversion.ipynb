{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Load cholec80 transforms and translate to different python module with same functionality. Also translate from yaml file to pandas pickle format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'transforms'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/hil/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'transforms'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b7352244a95e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mdatabase_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../configs/cholec80_transforms.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transforms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0mdatabase_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hil/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hil/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hil/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'transforms'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import load_yaml, save_yaml\n",
    "\n",
    "servers = load_yaml('../configs/servers.yml')\n",
    "server = servers['local']\n",
    "\n",
    "databases = load_yaml('../configs/cholec80_transforms.yml')\n",
    "database = databases['databases'][0]\n",
    "\n",
    "# files, prefix in db], transform {module, type, kwargs}, database {name, prefix}\n",
    "database_df = pd.DataFrame(columns=['database', 'train', 'file', 'pre_transforms', 'aug_transforms', 'auxiliary'])\n",
    "\n",
    "aug_transforms = [\n",
    "    # {'module': 'torchvision.transforms', 'type': 'ConvertImageDtype', 'kwargs': {'dtype': torch.float32}},  # works, but kills worker (shared memory too small, might work on server) normalizes image already to [0., 1.]\n",
    "    # {'module': 'torchvision.transforms', 'type': 'ColorJitter', 'kwargs': {'brightness': 0.5}}, # rework transforms here\n",
    "    {'module': 'torchvision.transforms', 'type': 'RandomGrayscale', 'kwargs': {'p': 0.5}},      # GaussianBlur, \n",
    "    {'module': 'torchvision.transforms', 'type': 'RandomVerticalFlip', 'kwargs': {'p': 0.5}},   # RandomVerticalFlip & Horizontal -> to comp sq\n",
    "    {'module': 'torchvision.transforms', 'type': 'RandomHorizontalFlip', 'kwargs': {'p': 0.5}}  # RandomErasing, ConvertImageDtype\n",
    "]\n",
    "\n",
    "# load transforms and convert them to other module's callables\n",
    "key_dict = {\n",
    "    'Crop': 'Crop',\n",
    "    'Resize': 'Resize'\n",
    "}\n",
    "\n",
    "for db_idx, db in enumerate(databases['databases']):\n",
    "\n",
    "    for t_idx, old_transforms in enumerate(db['transforms']):\n",
    "        pre_transforms = []\n",
    "        for old_transform in old_transforms:\n",
    "            # 'Crop' -> 'crop', shape -> height, width, top_left_corner -> top, left\n",
    "            # 'Resize' -> 'resize', dsize -> size\n",
    "            transform = {}\n",
    "            for key, value in old_transform.items():\n",
    "                if key == 'Crop':\n",
    "                    transform = {\n",
    "                        'module': 'utils.transforms',\n",
    "                        'type': 'Crop',\n",
    "                        'kwargs': {\n",
    "                            'top_left_corner': value['top_left_corner'],\n",
    "                            'shape': value['shape'][::-1],\n",
    "                            'order': 'chw'\n",
    "                        }\n",
    "                    }\n",
    "                elif key == 'Resize':\n",
    "                    transform = {\n",
    "                        'module': 'torchvision.transforms',\n",
    "                        'type': 'Resize',\n",
    "                        'kwargs': {\n",
    "                            'size': value['dsize'][::-1]\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "\n",
    "                else:\n",
    "                    raise ValueError('Key not known')\n",
    "\n",
    "            pre_transforms.append(transform)                \n",
    "        \n",
    "        df_row = {\n",
    "            'database': database['name'],\n",
    "            'train': True,\n",
    "            'file': {'name': database['videos']['files'][t_idx], 'path': database['videos']['prefix']}, \n",
    "            'pre_transforms': pre_transforms,\n",
    "            'aug_transforms': aug_transforms,\n",
    "            'auxiliary': {}\n",
    "        }\n",
    "        database_df = database_df.append(df_row, ignore_index=True)\n",
    "\n",
    "database_df.to_pickle('../configs/cholec80_transforms.pkl')\n",
    "print('pre-transforms:\\n', database_df.pre_transforms[0])\n",
    "print('aug-transforms:\\n', database_df.aug_transforms[0])\n",
    "database_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pre-transforms:\n [{'module': 'utils.transforms', 'type': 'Crop', 'kwargs': {'top_left_corner': [58, 142], 'shape': [554, 416], 'order': 'chw'}}, {'module': 'torchvision.transforms', 'type': 'Resize', 'kwargs': {'size': [480, 640]}}]\naug-transforms:\n [{'module': 'torchvision.transforms', 'type': 'RandomGrayscale', 'kwargs': {'p': 0.1}}, {'module': 'torchvision.transforms', 'type': 'RandomVerticalFlip', 'kwargs': {'p': 0.5}}, {'module': 'torchvision.transforms', 'type': 'RandomHorizontalFlip', 'kwargs': {'p': 0.5}}]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   database  train                                               file  \\\n",
       "0  cholec80   True  {'name': 'video01_short.mp4', 'path': 'sample_...   \n",
       "1  cholec80   True  {'name': 'video02_short.mp4', 'path': 'sample_...   \n",
       "2  cholec80   True  {'name': 'video03_short.mp4', 'path': 'sample_...   \n",
       "3  cholec80   True  {'name': 'video04_short.mp4', 'path': 'sample_...   \n",
       "4  cholec80  False  {'name': 'video01_short.mp4', 'path': 'sample_...   \n",
       "5  cholec80  False  {'name': 'video02_short.mp4', 'path': 'sample_...   \n",
       "\n",
       "                                      pre_transforms  \\\n",
       "0  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "1  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "2  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "3  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "4  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "5  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "\n",
       "                                      aug_transforms auxiliary  \n",
       "0  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "1  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "2  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "3  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "4  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "5  [{'module': 'torchvision.transforms', 'type': ...        {}  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>database</th>\n      <th>train</th>\n      <th>file</th>\n      <th>pre_transforms</th>\n      <th>aug_transforms</th>\n      <th>auxiliary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video01_short.mp4', 'path': 'sample_...</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video02_short.mp4', 'path': 'sample_...</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video03_short.mp4', 'path': 'sample_...</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video04_short.mp4', 'path': 'sample_...</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cholec80</td>\n      <td>False</td>\n      <td>{'name': 'video01_short.mp4', 'path': 'sample_...</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cholec80</td>\n      <td>False</td>\n      <td>{'name': 'video02_short.mp4', 'path': 'sample_...</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# create dummy df\n",
    "database_df = pd.DataFrame(columns=['database', 'train', 'file', 'pre_transforms', 'aug_transforms', 'auxiliary'])\n",
    "\n",
    "pre_transforms = [\n",
    "    {'module': 'utils.transforms', 'type': 'Crop', 'kwargs': {'top_left_corner': [58, 142], 'shape': [554, 416], 'order': 'chw'}},\n",
    "    {'module': 'torchvision.transforms', 'type': 'Resize', 'kwargs': {'size': [480, 640]}}\n",
    "]\n",
    "\n",
    "aug_transforms = [\n",
    "    # {'module': 'torchvision.transforms', 'type': 'ConvertImageDtype', 'kwargs': {'dtype': torch.float32}},  # works, but kills worker (shared memory too small, might work on server) normalizes image already to [0., 1.]\n",
    "    # {'module': 'torchvision.transforms', 'type': 'ColorJitter', 'kwargs': {'brightness': 0.1, 'contrast': 0.1, 'saturation': 0.1, 'hue': 0.1}}, # rework transforms here\n",
    "    {'module': 'torchvision.transforms', 'type': 'RandomGrayscale', 'kwargs': {'p': 0.1}},      # GaussianBlur, \n",
    "    {'module': 'torchvision.transforms', 'type': 'RandomVerticalFlip', 'kwargs': {'p': 0.5}},    # RandomVerticalFlip & Horizontal\n",
    "    {'module': 'torchvision.transforms', 'type': 'RandomHorizontalFlip', 'kwargs': {'p': 0.5}}    # RandomErasing, ConvertImageDtype\n",
    "    # {'module': 'torchvision.transforms', 'type': 'GaussianBlur', 'kwargs': {'kernel_size': 9, 'sigma': (0.1, 1.)}}\n",
    "]\n",
    "\n",
    "for i in range(4):\n",
    "    database_df = database_df.append(\n",
    "        {\n",
    "            'database': 'cholec80',\n",
    "            'train': True,\n",
    "            'file': {\n",
    "                'name': 'video0{}_short.mp4'.format(i+1),\n",
    "                'path': 'sample_videos'\n",
    "            },\n",
    "            'pre_transforms': pre_transforms,\n",
    "            'aug_transforms': aug_transforms,\n",
    "            'auxiliary': {}\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "# add test set\n",
    "for i in range(2):\n",
    "    database_df = database_df.append(\n",
    "        {\n",
    "            'database': 'cholec80',\n",
    "            'train': False,\n",
    "            'file': {\n",
    "                'name': 'video0{}_short.mp4'.format(i+1),\n",
    "                'path': 'sample_videos'\n",
    "            },\n",
    "            'pre_transforms': pre_transforms,\n",
    "            'aug_transforms': aug_transforms,\n",
    "            'auxiliary': {}\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "\n",
    "database_df.to_pickle('../configs/cholec80_dummy_transforms.pkl')\n",
    "print('pre-transforms:\\n', database_df.pre_transforms[0])\n",
    "print('aug-transforms:\\n', database_df.aug_transforms[0])\n",
    "database_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pre-transforms:\n [{'module': 'utils.transforms', 'type': 'Crop', 'kwargs': {'top_left_corner': [58, 142], 'shape': [554, 416], 'order': 'chw'}}, {'module': 'torchvision.transforms', 'type': 'Resize', 'kwargs': {'size': [480, 640]}}]\naug-transforms:\n [{'module': 'torchvision.transforms', 'type': 'RandomGrayscale', 'kwargs': {'p': 0.5}}, {'module': 'torchvision.transforms', 'type': 'RandomVerticalFlip', 'kwargs': {'p': 0.5}}, {'module': 'torchvision.transforms', 'type': 'RandomHorizontalFlip', 'kwargs': {'p': 0.5}}]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    database train                                       file  \\\n",
       "0   cholec80  True  {'name': 'video01.mp4', 'path': 'videos'}   \n",
       "1   cholec80  True  {'name': 'video02.mp4', 'path': 'videos'}   \n",
       "2   cholec80  True  {'name': 'video03.mp4', 'path': 'videos'}   \n",
       "3   cholec80  True  {'name': 'video04.mp4', 'path': 'videos'}   \n",
       "4   cholec80  True  {'name': 'video05.mp4', 'path': 'videos'}   \n",
       "..       ...   ...                                        ...   \n",
       "70  cholec80  True  {'name': 'video17.mp4', 'path': 'videos'}   \n",
       "71  cholec80  True  {'name': 'video18.mp4', 'path': 'videos'}   \n",
       "72  cholec80  True  {'name': 'video19.mp4', 'path': 'videos'}   \n",
       "73  cholec80  True  {'name': 'video20.mp4', 'path': 'videos'}   \n",
       "74  cholec80  True  {'name': 'video22.mp4', 'path': 'videos'}   \n",
       "\n",
       "                                       pre_transforms  \\\n",
       "0   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "1   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "2   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "3   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "4   [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "..                                                ...   \n",
       "70  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "71  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "72  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "73  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "74  [{'module': 'utils.transforms', 'type': 'Crop'...   \n",
       "\n",
       "                                       aug_transforms auxiliary  \n",
       "0   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "1   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "2   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "3   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "4   [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "..                                                ...       ...  \n",
       "70  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "71  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "72  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "73  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "74  [{'module': 'torchvision.transforms', 'type': ...        {}  \n",
       "\n",
       "[75 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>database</th>\n      <th>train</th>\n      <th>file</th>\n      <th>pre_transforms</th>\n      <th>aug_transforms</th>\n      <th>auxiliary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video01.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video02.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video03.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video04.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video05.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video17.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video18.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video19.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video20.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>cholec80</td>\n      <td>True</td>\n      <td>{'name': 'video22.mp4', 'path': 'videos'}</td>\n      <td>[{'module': 'utils.transforms', 'type': 'Crop'...</td>\n      <td>[{'module': 'torchvision.transforms', 'type': ...</td>\n      <td>{}</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "database_df = pd.read_pickle('../configs/cholec80_transforms.pkl')\n",
    "\n",
    "print('pre-transforms:\\n', database_df.pre_transforms[0])\n",
    "print('aug-transforms:\\n', database_df.aug_transforms[0])\n",
    "database_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}