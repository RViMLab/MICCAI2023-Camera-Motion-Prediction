{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from lightning_modules import DeepImageHomographyEstimationModuleBackbone\n",
    "from utils.io import load_yaml\n",
    "\n",
    "# load best model\\n\",\n",
    "prefix = '/home/martin/Tresors/homography_imitation_learning_logs/deep_image_homography_estimation_backbone/version_2'\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/unsupervised_deep_homography_estimation_backbone/version_0'\n",
    "configs = load_yaml(os.path.join(prefix, 'config.yml'))\n",
    "model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=49.ckpt'), shape=configs['model']['shape'])\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print('Running with CUDA backend.')\n",
    "    device = 'cuda'\n",
    "\n",
    "model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from datasets import ImageSequenceDataset\n",
    "\n",
    "prefix = '/media/martin/Samsung_T5/data/endoscopic_data/camera_motion_separated_npy/with_camera_motion'\n",
    "df_name = 'log_with_camera_motion_seq_len_2.pkl'\n",
    "df = pd.read_pickle(os.path.join(prefix, df_name))\n",
    "ds = ImageSequenceDataset(df, prefix, ToTensor())\n",
    "dl = DataLoader(ds, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn.functional import mse_loss\n",
    "from kornia import tensor_to_image, get_perspective_transform, warp_perspective\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.processing import image_edges, four_point_homography_to_matrix\n",
    "\n",
    "sample = next(iter(dl))\n",
    "sample[0].shape\n",
    "\n",
    "mask0 = torch.ones([1, 1, sample[0].shape[-2], sample[0].shape[-1]], device=device, requires_grad=True)\n",
    "mask1 = torch.ones([1, 1, sample[0].shape[-2], sample[0].shape[-1]], device=device, requires_grad=True)\n",
    "zeros = torch.zeros([1, 1, sample[0].shape[-2], sample[0].shape[-1]], device=device)\n",
    "\n",
    "# optim = Adam([mask0, mask1], lr=1e-2)\n",
    "optim = Adam([mask0], lr=1e-2)\n",
    "\n",
    "# find attention mask\n",
    "model = model.train()\n",
    "\n",
    "batch = next(iter(dl))\n",
    "img0 = batch[0].to(device)\n",
    "img1 = batch[1].to(device)\n",
    "\n",
    "duv_target = model(img0, img1).detach()\n",
    "N = 2000\n",
    "for e in range(N):\n",
    "    print('\\rEpoch {}/{}'.format(e, N), end='')\n",
    "    optim.zero_grad()\n",
    "    img0_masked = img0.mul(torch.sigmoid(mask0))\n",
    "    img1_masked = img1.mul(torch.sigmoid(mask1))\n",
    "\n",
    "    duv = model(img0_masked, img1_masked)\n",
    "\n",
    "    uv = image_edges(img0)\n",
    "    wrp_uv = uv + duv\n",
    "    h = get_perspective_transform(uv.flip(-1), wrp_uv.flip(-1))\n",
    "    warped_mask0 = warp_perspective(mask0, torch.inverse(h), mask0.shape[-2:])\n",
    "\n",
    "    loss = 10*mse_loss(duv, duv_target) + mse_loss(torch.sigmoid(mask0), zeros) + mse_loss(torch.sigmoid(mask1), zeros) + mse_loss(torch.sigmoid(warped_mask0), torch.sigmoid(mask1))\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "print('h_target', duv_target)\n",
    "print('h', duv)\n",
    "\n",
    "img0_masked = img0.mul(torch.sigmoid(mask0))\n",
    "img1_masked = img1.mul(torch.sigmoid(mask1))\n",
    "\n",
    "img0_masked = tensor_to_image(img0_masked)\n",
    "img1_masked = tensor_to_image(img1_masked)\n",
    "img0 = tensor_to_image(img0)\n",
    "img1 = tensor_to_image(img1)\n",
    "mask0 = tensor_to_image(torch.sigmoid(mask0))\n",
    "mask1 = tensor_to_image(torch.sigmoid(mask1))\n",
    "\n",
    "plt.imshow(img0_masked)\n",
    "plt.show()\n",
    "plt.imshow(img0)\n",
    "plt.show()\n",
    "plt.imshow(mask0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch110')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "de43f3610355f051a4a7d1ec68e5cd39983800d0bb5000cb4a591287222bab46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
