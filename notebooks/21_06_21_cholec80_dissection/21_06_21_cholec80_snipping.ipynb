{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from dotmap import DotMap\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from utils.io import recursive_scan2df, load_yaml\n",
    "from utils.sampling import ConsecutiveSequences"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "server = 'local'\n",
    "server = DotMap(load_yaml('../../config/servers.yml')[server])\n",
    "\n",
    "database_name = 'cholec80_splits'\n",
    "database_df = recursive_scan2df(os.path.join(server.database.location, database_name), postfix='.mp4')\n",
    "database_df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              file   folder\n",
       "0      split_0.mp4  video36\n",
       "1      split_1.mp4  video36\n",
       "2      split_2.mp4  video36\n",
       "3      split_3.mp4  video36\n",
       "4      split_4.mp4  video36\n",
       "...            ...      ...\n",
       "3030  split_30.mp4  video35\n",
       "3031  split_31.mp4  video35\n",
       "3032  split_32.mp4  video35\n",
       "3033  split_33.mp4  video35\n",
       "3034  split_34.mp4  video35\n",
       "\n",
       "[3035 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>split_0.mp4</td>\n",
       "      <td>video36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>split_1.mp4</td>\n",
       "      <td>video36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>split_2.mp4</td>\n",
       "      <td>video36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>split_3.mp4</td>\n",
       "      <td>video36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>split_4.mp4</td>\n",
       "      <td>video36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>split_30.mp4</td>\n",
       "      <td>video35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3031</th>\n",
       "      <td>split_31.mp4</td>\n",
       "      <td>video35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>split_32.mp4</td>\n",
       "      <td>video35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>split_33.mp4</td>\n",
       "      <td>video35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>split_34.mp4</td>\n",
       "      <td>video35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3035 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# individual database post-processing\n",
    "condition_df = pd.read_csv('20_10_endoscopic_datasets - cholec80_splits.csv')\n",
    "\n",
    "database_df_ext = database_df.copy()\n",
    "database_df_ext['vid_idx'] = database_df.folder.apply(lambda x: int(x.replace('video', '')))\n",
    "database_df_ext['split_idx'] = database_df.file.apply(lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "# keep videos to use and discard splits where [change of zoom] or [shift] or [theater] or [status indicator]\n",
    "init_len = len(database_df_ext)\n",
    "for _, row in condition_df.iterrows():\n",
    "    if row.use == False:\n",
    "        database_df_ext = database_df_ext.drop(database_df_ext[database_df_ext.vid_idx == row.video].index)\n",
    "    else:\n",
    "        if not condition_df['change of zoom / split'][condition_df.video == row.video].isna().values:\n",
    "            idcs = [int(xi) for xi in condition_df['change of zoom / split'][condition_df.video == row.video].values[0].split(',')]\n",
    "            splits = ~database_df_ext[database_df_ext.vid_idx == row.video].split_idx.isin(idcs)\n",
    "            splits = splits[splits == False]\n",
    "            database_df_ext = database_df_ext.drop(splits.index)\n",
    "        if not condition_df['shift / split'][condition_df.video == row.video].isna().values:\n",
    "            idcs = [int(xi) for xi in condition_df['shift / split'][condition_df.video == row.video].values[0].split(',')]\n",
    "            splits = ~database_df_ext[database_df_ext.vid_idx == row.video].split_idx.isin(idcs)\n",
    "            splits = splits[splits == False]\n",
    "            database_df_ext = database_df_ext.drop(splits.index)\n",
    "        if not condition_df['theater / split'][condition_df.video == row.video].isna().values:\n",
    "            idcs = [int(xi) for xi in condition_df['theater / split'][condition_df.video == row.video].values[0].split(',')]\n",
    "            splits = ~database_df_ext[database_df_ext.vid_idx == row.video].split_idx.isin(idcs)\n",
    "            splits = splits[splits == False]\n",
    "            database_df_ext = database_df_ext.drop(splits.index)\n",
    "        if not condition_df['status indicator / split'][condition_df.video == row.video].isna().values:\n",
    "            idcs = [int(xi) for xi in condition_df['status indicator / split'][condition_df.video == row.video].values[0].split(',')]\n",
    "            splits = ~database_df_ext[database_df_ext.vid_idx == row.video].split_idx.isin(idcs)\n",
    "            splits = splits[splits == False]\n",
    "            database_df_ext = database_df_ext.drop(splits.index)\n",
    "print('Removed {} splits. Left with {}/{} splits'.format(init_len - len(database_df_ext), len(database_df_ext), init_len))\n",
    "database_df = database_df_ext\n",
    "database_df_ext\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Removed 892 splits. Left with 2143/3035 splits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              file   folder  vid_idx  split_idx\n",
       "0      split_0.mp4  video36       36          0\n",
       "1      split_1.mp4  video36       36          1\n",
       "2      split_2.mp4  video36       36          2\n",
       "3      split_3.mp4  video36       36          3\n",
       "4      split_4.mp4  video36       36          4\n",
       "...            ...      ...      ...        ...\n",
       "3028  split_28.mp4  video35       35         28\n",
       "3031  split_31.mp4  video35       35         31\n",
       "3032  split_32.mp4  video35       35         32\n",
       "3033  split_33.mp4  video35       35         33\n",
       "3034  split_34.mp4  video35       35         34\n",
       "\n",
       "[2143 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>folder</th>\n",
       "      <th>vid_idx</th>\n",
       "      <th>split_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>split_0.mp4</td>\n",
       "      <td>video36</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>split_1.mp4</td>\n",
       "      <td>video36</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>split_2.mp4</td>\n",
       "      <td>video36</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>split_3.mp4</td>\n",
       "      <td>video36</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>split_4.mp4</td>\n",
       "      <td>video36</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>split_28.mp4</td>\n",
       "      <td>video35</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3031</th>\n",
       "      <td>split_31.mp4</td>\n",
       "      <td>video35</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032</th>\n",
       "      <td>split_32.mp4</td>\n",
       "      <td>video35</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>split_33.mp4</td>\n",
       "      <td>video35</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>split_34.mp4</td>\n",
       "      <td>video35</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2143 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "p = 0.2\n",
    "N = int(p*len(database_df))\n",
    "\n",
    "database_df['train'] = True\n",
    "database_df_sample = database_df.sample(N)\n",
    "\n",
    "print(len(database_df_sample)/len(database_df))\n",
    "database_df_sample.train = False\n",
    "\n",
    "database_df.update(database_df_sample)\n",
    "\n",
    "n1 = len(database_df[database_df.train == False])\n",
    "n2 = len(database_df[database_df.train == True])\n",
    "\n",
    "database_df = database_df.groupby('vid_idx').apply(lambda dfg: dfg.sample(3)).reset_index(drop=True)\n",
    "database_df.to_pickle('cholec80_cleaned_samples.pkl')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1997200186654223\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "from datasets import VideoDataset\n",
    "from utils.io import load_pickle, save_pickle\n",
    "from utils.processing import endoscopy\n",
    "\n",
    "visualize = True\n",
    "\n",
    "database_df = pd.read_pickle('cholec80_cleaned_samples.pkl')\n",
    "# database_df = database_df.groupby('vid_idx').apply(lambda dfg: dfg.sample(3)).reset_index(drop=True)\n",
    "# database_df = database_df[database_df.train == False]\n",
    "# database_df = database_df.iloc[78:]\n",
    "\n",
    "video_paths = [os.path.join(server.database.location, database_name, x.folder, x.file) for _, x in database_df.iterrows()]\n",
    "frame_rate = 5\n",
    "duration = 10\n",
    "clip_length_in_frames = int(frame_rate*duration)\n",
    "num_workers = 8\n",
    "\n",
    "# load metadata, if existing\n",
    "metadata_name = 'cholec80_splits_metadata.pkl' # -> 'cholec80_splits_metadata_full.pkl'\n",
    "metadata = None\n",
    "print('\\nLooking for {}'.format(metadata_name))\n",
    "if os.path.exists(metadata_name):\n",
    "    metadata = load_pickle(metadata_name)\n",
    "    print('Found.')\n",
    "else:\n",
    "    print('Could not find {}. Generating metadata.'.format(metadata_name))\n",
    "\n",
    "video_ds = VideoDataset(\n",
    "            video_paths=video_paths,\n",
    "            clip_length_in_frames=clip_length_in_frames,\n",
    "            frames_between_clips=clip_length_in_frames,\n",
    "            frame_rate=frame_rate,\n",
    "            precomputed_metadata=metadata,\n",
    "            num_workers=num_workers,\n",
    "            permute=False,\n",
    "            convert_dtype=False\n",
    ")\n",
    "\n",
    "# store metadata\n",
    "if not os.path.exists(metadata_name):\n",
    "    metadata = video_ds.metadata\n",
    "    save_pickle(metadata_name, metadata)\n",
    "\n",
    "# prepare database\n",
    "database_transforms = pd.DataFrame(\n",
    "    columns=['database', 'train', 'file', 'pre_transforms', 'aug_transforms', 'auxiliary']\n",
    ")\n",
    "\n",
    "# boundary detection parameters\n",
    "illumination_th = 0.998\n",
    "detected_video_idx = -1\n",
    "\n",
    "\n",
    "# iterate through each video\n",
    "for batch in video_ds:\n",
    "    video, augmented_video, frame_rate, video_fps, video_idx, idx = batch\n",
    "    if video_idx == detected_video_idx:\n",
    "        continue\n",
    "    video_path = database_df.iloc[video_idx].folder\n",
    "    video_name = database_df.iloc[video_idx].file\n",
    "\n",
    "    for frame in video:\n",
    "        frame = frame.numpy()\n",
    "        paddding = 5\n",
    "        frame = frame[paddding:-paddding] # add to crop\n",
    "        \n",
    "        # pre-process frame\n",
    "        mask = endoscopy.bilateralSegmentation(frame, th=0.05)\n",
    "        center, radius = endoscopy.boundary_detection.ransacBoundaryCircle(mask, fit='numeric', n_iter=1, n_pts=100)\n",
    "\n",
    "        if radius is not None:\n",
    "            illumination = endoscopy.illuminationLevel(mask, center, radius)\n",
    "\n",
    "            print('\\rIllumination level: {}, threshold: {}, video {} - {}/{}, idx {}/{}, shape: {}'.format(illumination, illumination > illumination_th, video_idx+1, video_path, video_name, idx+1, len(video_ds), video.shape), end='')\n",
    "\n",
    "            top_left, shape = endoscopy.maxRectangleInCircle(frame.shape, center, radius)\n",
    "            center, radius = center.astype(int), int(radius)\n",
    "            top_left, shape = top_left.astype(int), tuple(map(int, shape))\n",
    "\n",
    "            if illumination > illumination_th:\n",
    "                if visualize:\n",
    "                    cv2.circle(frame, (center[1], center[0]), radius, (255, 255, 0), 2)\n",
    "                    cv2.rectangle(frame, (top_left[1], top_left[0]), (top_left[1] + shape[1], top_left[0] + shape[0]), (255, 255, 0), 2)\n",
    "\n",
    "                    cv2.imshow('img', frame[...,::-1])\n",
    "                    cv2.imshow('mask', mask)\n",
    "                    cv2.waitKey()\n",
    "\n",
    "                detected_video_idx = video_idx\n",
    "\n",
    "                inp = input()\n",
    "                if inp == 'y':\n",
    "                    row = {\n",
    "                        'database': 'cholec80_splits',\n",
    "                        'train': database_df.iloc[video_idx].train,\n",
    "                        'file': {\n",
    "                            'name': video_name,\n",
    "                            'path': video_path\n",
    "                        },\n",
    "                        'pre_transforms': [\n",
    "                            {\n",
    "                                'module': 'utils.transforms',\n",
    "                                'type': 'Crop',\n",
    "                                'kwargs': {\n",
    "                                    'top_left_corner': [top_left[0]+paddding, top_left[1]],\n",
    "                                    'shape': [shape[0]+paddding, shape[1]],\n",
    "                                    'order': 'chw'\n",
    "                                }\n",
    "                            },\n",
    "                            {\n",
    "                                'module': 'torchvision.transforms',\n",
    "                                'type': 'Resize',\n",
    "                                'kwargs': {\n",
    "                                    'size': [240, 320]\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        'aug_transforms': [],\n",
    "                        'auxiliary': {}\n",
    "                    }\n",
    "\n",
    "                database_transforms = database_transforms.append(row, ignore_index=True)\n",
    "                database_transforms.to_pickle('cholec80_splits_transforms.pkl')\n",
    "                break\n",
    "        else:\n",
    "            print('\\rRadius not found.', end='')\n",
    "\n",
    "# database_transforms.to_pickle('cholec80_splits_transforms.pkl')\n",
    "if visualize:\n",
    "    cv2.destroyAllWindows()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Looking for cholec80_splits_metadata.pkl\n",
      "Found.\n",
      "Illumination level: 0.9994102301005316, threshold: True, video 1 - video01/split_3.mp4, idx 1/1170, shape: torch.Size([50, 480, 854, 3])"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# create test set\n",
    "database_transforms = pd.read_pickle('cholec80_splits_transforms.pkl')\n",
    "\n",
    "p = 0.2\n",
    "N = int(p*len(database_transforms))\n",
    "\n",
    "database_transforms['train'] = True\n",
    "database_transforms_sample = database_transforms.sample(N)\n",
    "\n",
    "database_transforms_sample.train = False\n",
    "\n",
    "database_transforms.update(database_transforms_sample)\n",
    "\n",
    "n1 = len(database_transforms[database_transforms.train == False])\n",
    "n2 = len(database_transforms[database_transforms.train == True])\n",
    "print(n1/(n1+n2))\n",
    "\n",
    "database_transforms.to_pickle('cholec80_splits_transforms.pkl')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.19969666329625885\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotmap import DotMap\n",
    "\n",
    "from utils.io import load_yaml\n",
    "from utils.io import load_pickle, save_pickle\n",
    "from utils.transforms import anyDictListToCompose\n",
    "from lightning_data_modules import VideoDataModule\n",
    "\n",
    "\n",
    "meta_df_name = 'cholec80_splits_transforms.pkl'\n",
    "meta_df = pd.read_pickle(meta_df_name)\n",
    "meta_df.aug_transforms = None  # no transforms for evaluation\n",
    "\n",
    "test_md_name = 'cholec80_splits_test_md.pkl'\n",
    "test_md = None\n",
    "print('\\nLooking for {}'.format(test_md_name))\n",
    "if os.path.exists(test_md_name):\n",
    "    test_md = load_pickle(test_md_name)\n",
    "    print('Found.')\n",
    "else:\n",
    "    print('Could not find {}. Generating metadata.'.format(test_md_name))\n",
    "\n",
    "# load cholec80 splits\n",
    "prefix = server.database.location\n",
    "clip_length_in_frames = 10\n",
    "frames_between_clips = clip_length_in_frames\n",
    "frame_rate = 5\n",
    "train_split = 0.8\n",
    "batch_size = 1\n",
    "num_workers = 4\n",
    "random_state = 42\n",
    "\n",
    "dm = VideoDataModule(\n",
    "    meta_df,\n",
    "    prefix=prefix,\n",
    "    clip_length_in_frames=clip_length_in_frames,\n",
    "    frames_between_clips=frames_between_clips   ,\n",
    "    frame_rate=frame_rate,\n",
    "    train_split=train_split,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    random_state=random_state,\n",
    "    test_metadata=test_md\n",
    ")\n",
    "\n",
    "_, _, test_md = dm.setup('test')\n",
    "\n",
    "# store metadata\n",
    "save_pickle(test_md_name, test_md)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Looking for cholec80_splits_test_md.pkl\n",
      "Found.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from kornia import tensor_to_image\n",
    "\n",
    "test_dl = dm.test_dataloader()\n",
    "\n",
    "for batch in tqdm(test_dl):\n",
    "    vid, aug_vid, frame_rate, video_fps, video_idx, idx = batch\n",
    "\n",
    "    for frame in vid[0]: # BxNxCxHxW\n",
    "        cv2.imshow('frame', tensor_to_image(frame))\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/11850 [00:00<?, ?it/s]/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torchvision/io/video.py:116: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
      "  \"The pts_unit 'pts' gives wrong results and will be removed in a \"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "inp = input()\n",
    "\n",
    "if inp == 'y':\n",
    "    print('keep')\n",
    "else:\n",
    "    print('discard')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "discard\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efe34164bbb50e70fce224383f42acab6a26dd9dc9fafc86c4e503220a8c76a1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('hil': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}