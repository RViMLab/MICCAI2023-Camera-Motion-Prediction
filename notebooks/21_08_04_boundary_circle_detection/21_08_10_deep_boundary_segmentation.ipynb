{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py:164: DeprecationWarning: `configure_inline_support` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.configure_inline_support()`\n",
      "  configure_inline_support(ip, backend)\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/matplotlib_inline/config.py:66: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from lightning_modules.image_segmentation import ImageSegmentationModule\n",
    "from utils.io import load_yaml\n",
    "\n",
    "\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/boundary_image_segmentation/unet/resnet/34/tiny/version_4'\n",
    "# checkpoint = 'epoch=192-step=771.ckpt'\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/boundary_image_segmentation/unet/efficient_net/b0/version_0'\n",
    "# checkpoint = 'epoch=28-step=869.ckpt'\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/boundary_image_segmentation/deeplabv3p/efficient_net/b0/version_0'\n",
    "# checkpoint = 'epoch=49-step=1499.ckpt'\n",
    "prefix = '/home/martin/Tresors/homography_imitation_learning_logs/boundary_image_segmentation/unet/resnet/34/version_0'\n",
    "checkpoint = 'epoch=35-step=1079.ckpt'\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/boundary_image_segmentation/deeplabv3p/resnet/34/version_0'\n",
    "# checkpoint = 'epoch=45-step=1379.ckpt'\n",
    "\n",
    "config = load_yaml(os.path.join(prefix, 'config.yml'))\n",
    "\n",
    "model = ImageSegmentationModule(**config['model'])\n",
    "model = model.load_from_checkpoint(os.path.join(prefix, 'checkpoints', checkpoint), **config['model'])\n",
    "model = model.eval()\n",
    "model.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from kornia.geometry import resize\n",
    "from kornia import image_to_tensor, tensor_to_image\n",
    "import torch\n",
    "\n",
    "from utils.io import recursive_scan2df\n",
    "from utils.sampling import ConsecutiveSequences, RandomSequences\n",
    "from utils.processing import endoscopy\n",
    "\n",
    "prefix = '/media/martin/Samsung_T5/data/endoscopic_data/cholec80_splits'\n",
    "# prefix = '/media/martin/Samsung_T5/data/endoscopic_data/ROBUST_MIS_raw_data'\n",
    "df = recursive_scan2df(prefix, '.mp4')\n",
    "# df = recursive_scan2df(prefix, '.avi')\n",
    "N = 10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "\n",
    "paths = [os.path.join(prefix, row.folder, row.file) for _, row in df.sample(N).iterrows()]\n",
    "\n",
    "cs = RandomSequences(max_seq=100, paths=paths, seq_len=100)\n",
    "for frames in cs:\n",
    "    frames = image_to_tensor(frames)\n",
    "    frames = frames.to(model.device)\n",
    "    frames = frames.float()/255.\n",
    "    # frames = resize(frames, [270, 480])\n",
    "    segs = model(frames)\n",
    "    avg_seg = segs.mean(axis=0)\n",
    "\n",
    "    for seg, frame in zip(segs, frames):\n",
    "        seg = tensor_to_image(avg_seg, keepdim=False)\n",
    "        frame = tensor_to_image(frame, keepdim=False)\n",
    "\n",
    "        center, radius = endoscopy.ransacBoundaryCircle(seg*255, th=10, fit='numeric', n_pts=100, n_iter=1)\n",
    "\n",
    "        if radius is not None:\n",
    "            center, radius = center.astype(int), int(radius)\n",
    "        \n",
    "            top_left, shape = endoscopy.maxRectangleInCircle(seg.shape, center, radius)\n",
    "            top_left, shape = top_left.astype(int), tuple(map(int, shape))\n",
    "            cv2.circle(frame, (center[1], center[0]), radius, color=(1, 1, 0), thickness=2)\n",
    "            cv2.rectangle(frame, (top_left[1], top_left[0]), (top_left[1]+shape[1], top_left[0]+shape[0]), (1, 1, 0), thickness=2)\n",
    "\n",
    "            # crop = endoscopy.crop(frame, top_left, shape)\n",
    "            # cv2.imshow('crop', crop)\n",
    "\n",
    "        mask = endoscopy.bilateralSegmentation(frame*255, th=0.01)\n",
    "        center, radius = endoscopy.ransacBoundaryCircle(mask, th=10, fit='numeric', n_pts=100, n_iter=1)\n",
    "\n",
    "        if radius is not None:\n",
    "            center, radius = center.astype(int), int(radius)\n",
    "            cv2.circle(frame, (center[1], center[0]), radius, color=(1, 0, 1), thickness=2)\n",
    "\n",
    "        cv2.imshow('seg', seg)\n",
    "        cv2.imshow('frames', frame)\n",
    "        cv2.waitKey()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199, device: cuda:0, hxw: 480x854\n",
      "Total time:  1.2827739715576172\n",
      "Avg time:  0.006446100359586016\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from kornia import image_to_tensor, tensor_to_image, resize\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from utils.io import recursive_scan2df\n",
    "from utils.sampling import ConsecutiveSequences, RandomSequences\n",
    "from utils.processing import endoscopy\n",
    "\n",
    "prefix = '/media/martin/Samsung_T5/data/endoscopic_data/cholec80_splits'\n",
    "# prefix = '/media/martin/Samsung_T5/data/endoscopic_data/ROBUST_MIS_raw_data'\n",
    "df = recursive_scan2df(prefix, '.mp4')\n",
    "# df = recursive_scan2df(prefix, '.avi')\n",
    "N = 10\n",
    "inferences = 200\n",
    "frame_cnt = 0\n",
    "total_time = 0\n",
    "\n",
    "paths = [os.path.join(prefix, row.folder, row.file) for _, row in df.sample(N).iterrows()]\n",
    "exit = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "# model = model.to('cpu')\n",
    "\n",
    "cs = RandomSequences(max_seq=100, paths=paths, seq_len=100)\n",
    "for frames in cs:\n",
    "    for frame in frames:\n",
    "        if frame_cnt >= inferences - 1:\n",
    "            exit = True\n",
    "            break\n",
    "        start = time.time()\n",
    "        frame = image_to_tensor(frame, keepdim=False)\n",
    "        frame = frame.to(model.device)\n",
    "        frame = frame.float()/255.\n",
    "        # frames = resize(frames, [270, 480])\n",
    "        segs = model(frame)\n",
    "        total_time += time.time() - start\n",
    "\n",
    "        frame_cnt += 1\n",
    "        print('\\r{}, device: {}, hxw: {}x{}'.format(frame_cnt, model.device, frame.shape[-2], frame.shape[-1]), end='')\n",
    "    if exit:\n",
    "        break\n",
    "\n",
    "print('\\nTotal time: ', total_time)\n",
    "print('Avg time: ', total_time/frame_cnt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet\n",
    "# unet efficient_net b0\n",
    "# avg CPU time: 0.059 ms\n",
    "# avg GPU time: 0.008 ms\n",
    "# deeplabv3plus efficient_net b0\n",
    "# avg CPU time: 0.061 ms\n",
    "# avg GPU time: 0.008 ms\n",
    "\n",
    "# ResNet\n",
    "# unet resnet 34\n",
    "# avg CPU time: 0.083 ms\n",
    "# avg GPU time: 0.004 ms\n",
    "# deeplabv3plus resnet 34\n",
    "# avg CPU time: 0.076 ms\n",
    "# avg GPU time: 0.004 ms"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afa71c527eb733e1136cc2082f84ae0e6a163fb7798c0d02ae5d1d5f2b06a5f2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('hil': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
