{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit1b62a264e17d42af939496f2c9cc110f",
   "display_name": "Python 3.7.6 64-bit ('hil': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "efe34164bbb50e70fce224383f42acab6a26dd9dc9fafc86c4e503220a8c76a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.io import recursive_scan2df\n",
    "from utils import endoscopy"
   ]
  },
  {
   "source": [
    "# Real Setup Endoscopic View Segmentation\n",
    "Extract endoscopic circle from real setup images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'img/21_04_02_calib'\n",
    "df = recursive_scan2df('{}'.format(folder), '.npy')\n",
    "\n",
    "# sort\n",
    "df['index'] = df.file.apply(lambda x: int(x.replace('.', '_').split('_')[1]))\n",
    "df.index = df.index.astype(float)\n",
    "df = df.sort_values(by=['index'])\n",
    "\n",
    "# bilateral filter on rgb\n",
    "# doesnt matter if hsv or rgb -> hsv more intuitive though\n",
    "# radius: gradient over search\n",
    "# average area -> if mean > th, valid circle found, else previous or uninitialized\n",
    "\n",
    "crp_count = 0\n",
    "for _, row in df.iterrows():\n",
    "    img = np.load(os.path.join(folder, row.folder, row.file))\n",
    "\n",
    "    # mask\n",
    "    mask_bil_hsv = endoscopy.bilateralSegmentation(img.astype(np.uint8), th=0.05, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "    # circle\n",
    "    hsv_center, hsv_radius = endoscopy.boundaryCircle(mask_bil_hsv)\n",
    "    top_left, shape = endoscopy.boundaryRectangle(mask_bil_hsv)\n",
    "\n",
    "    if hsv_radius is None:\n",
    "        continue\n",
    "\n",
    "    # confidence measure for illumination\n",
    "    level = endoscopy.illuminationLevel(mask_bil_hsv, hsv_center, hsv_radius)\n",
    "\n",
    "    # crop\n",
    "    if level > 0.98:\n",
    "        inner_top_left, inner_shape = endoscopy.maxRectangleInCircle(img.shape, hsv_center, hsv_radius)\n",
    "        inner_top_left, inner_shape = inner_top_left.astype(np.int), tuple(map(int, inner_shape))\n",
    "        crp = endoscopy.crop(img, inner_top_left, inner_shape)\n",
    "        crp_count += 1\n",
    "        np.save('img/crop_{}.npy'.format(crp_count), crp)\n",
    "\n",
    "\n",
    "    # int\n",
    "    hsv_center, hsv_radius = hsv_center.astype(np.int), np.int(hsv_radius)\n",
    "    top_left, shape = top_left.astype(np.int), tuple(map(int, shape))\n",
    "\n",
    "    # bgr\n",
    "    mask_bil_hsv = cv2.cvtColor(mask_bil_hsv, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # draw\n",
    "    cv2.circle(img, (hsv_center[1], hsv_center[0]), hsv_radius, (255, 255, 0), 2)\n",
    "    cv2.circle(img, (hsv_center[1], hsv_center[0]), 2, (255, 255, 0), -1)\n",
    "\n",
    "    cv2.rectangle(img, (top_left[1], top_left[0]), (top_left[1] + shape[1], top_left[0] + shape[0]), (255, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.imshow('mask_bil_hsv', mask_bil_hsv)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "# Real Setup Homography Regression\n",
    "Regress real setup homography from calibration pattern"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.io import scan2df\n",
    "\n",
    "# homography estimation\n",
    "folder = 'img'\n",
    "crp_df = scan2df(folder, '.npy')\n",
    "\n",
    "for idx in range(len(crp_df) - 1):\n",
    "\n",
    "    crp_0 = np.load(os.path.join(crp_df.iloc[idx].folder, crp_df.iloc[idx].file))\n",
    "    crp_1 = np.load(os.path.join(crp_df.iloc[idx+1].folder, crp_df.iloc[idx+1].file))\n",
    "\n",
    "    # homography estimation\n",
    "    patternSize = (4, 11)\n",
    "\n",
    "    # convert to grayscale\n",
    "    crp_0 = cv2.cvtColor(crp_0.astype(np.float32), cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "    crp_1 = cv2.cvtColor(crp_1.astype(np.float32), cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "\n",
    "    # find points\n",
    "    found0, pts0 = cv2.findCirclesGrid(crp_0, patternSize=patternSize, flags=cv2.CALIB_CB_ASYMMETRIC_GRID)\n",
    "    found1, pts1 = cv2.findCirclesGrid(crp_1, patternSize=patternSize, flags=cv2.CALIB_CB_ASYMMETRIC_GRID)\n",
    "\n",
    "    if found0 and found1:\n",
    "        G, _ = cv2.findHomography(pts0, pts1, cv2.RANSAC)\n",
    "\n",
    "        wrp = cv2.warpPerspective(crp_0, G, crp_1.shape[-2:][::-1])\n",
    "\n",
    "        cv2.imshow('crp_0', crp_0)\n",
    "        cv2.imshow('crp_1', crp_1)\n",
    "        cv2.imshow('wrp', wrp)\n",
    "        cv2.imshow('error', np.abs(wrp - crp_1))\n",
    "        cv2.waitKey()\n",
    "    else:\n",
    "        print('Did not find points.')\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "# Real Setup Homography Regression\n",
    "Extract homography from real setup using trained model and classical feature-based method"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model input shape: [3, 480, 640]\n",
      "Running with CUDA backend.\n",
      "/home/martin/miniconda3/envs/hil/lib/python3.7/site-packages/kornia/geometry/transform/imgwarp.py:98: UserWarning: The align_corners default value has been changed. By default now is set True in order to match cv2.warpPerspective. In case you want to keep your previous behaviour set it to False. This warning will disappear in kornia > v0.6.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from kornia import image_to_tensor, tensor_to_image, warp_perspective\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.viz import yt_alpha_blend\n",
    "from utils.processing import FeatureHomographyEstimation, four_point_homography_to_matrix, image_edges\n",
    "from utils.io import recursive_scan2df, load_yaml\n",
    "from utils import endoscopy\n",
    "from lightning_modules import DeepImageHomographyEstimationModuleBackbone\n",
    "\n",
    "# load network\n",
    "prefix = '/home/martin/Tresors/homography_imitation_learning_logs/deep_image_homography_estimation_backbone/version_10'\n",
    "# prefix = '/home/martin/Tresors/homography_imitation_learning_logs/deep_image_homography_estimation_backbone_optimize_network/version_0'\n",
    "configs = load_yaml(os.path.join(prefix, 'config.yml'))\n",
    "model_input_shape = configs['model']['shape']\n",
    "model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=53-step=47573.ckpt'), shape=model_input_shape)\n",
    "# model = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(os.path.join(prefix, 'checkpoints/epoch=99-step=22099.ckpt'), shape=model_input_shape)\n",
    "\n",
    "print('Model input shape: {}'.format(model_input_shape))\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    print('Running with CUDA backend.')\n",
    "    device = 'cuda'\n",
    "\n",
    "model.to(device)\n",
    "model = model.eval()\n",
    "model.freeze()\n",
    "\n",
    "\n",
    "# classical esimation\n",
    "with_feature_estimation = False\n",
    "fd = cv2.xfeatures2d.SIFT_create()\n",
    "fh = FeatureHomographyEstimation(fd)\n",
    "\n",
    "# image buffer\n",
    "buffer = []\n",
    "\n",
    "# load data\n",
    "folder = 'img/21_04_02_abdomen'\n",
    "df = recursive_scan2df('{}'.format(folder), '.npy')\n",
    "\n",
    "# sort\n",
    "df['index'] = df.file.apply(lambda x: int(x.replace('.', '_').split('_')[1]))\n",
    "df.index = df.index.astype(float)\n",
    "df = df.sort_values(by=['index'])\n",
    "\n",
    "nth = 2\n",
    "for _, row in df.iloc[::nth].iterrows():\n",
    "    img = np.load(os.path.join(folder, row.folder, row.file))\n",
    "    marked_img = img.copy()\n",
    "\n",
    "    mask = endoscopy.bilateralSegmentation(img.astype(np.uint8), th=0.05)\n",
    "    center, radius = endoscopy.boundaryCircle(mask)\n",
    "    if radius is None:\n",
    "        continue\n",
    "\n",
    "    safety_margin = 10\n",
    "    if radius > safety_margin:\n",
    "        radius -= safety_margin  # safety margin\n",
    "    top_left, shape = endoscopy.maxRectangleInCircle(mask.shape, center, radius)\n",
    "\n",
    "    center, radius = center.astype(np.int), int(radius)\n",
    "    top_left, shape = top_left.astype(np.int), tuple(map(int, shape))\n",
    "\n",
    "    cv2.circle(marked_img, (center[1], center[0]), radius, (255, 255, 0), 2)\n",
    "    cv2.rectangle(marked_img, (top_left[1], top_left[0]), (top_left[1]+shape[1], top_left[0]+shape[0]), (255, 0, 255), 2)\n",
    "\n",
    "    # regress\n",
    "    crp = endoscopy.crop(img, top_left, shape)\n",
    "    if crp.shape[0] is 0:\n",
    "        continue\n",
    "\n",
    "    crp = cv2.resize(crp, (model_input_shape[2], model_input_shape[1]))\n",
    "\n",
    "    buffer.append(crp)\n",
    "    if len(buffer) > 2:\n",
    "        buffer.pop(0)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # classical feature prediction\n",
    "    img, wrp = buffer[0], buffer[1]\n",
    "    H_ft, duv_ft = fh(img.astype(np.uint8), wrp.astype(np.uint8))\n",
    "    wrp_ft_pred = cv2.warpPerspective(img, H_ft, (img.shape[1], img.shape[0]))\n",
    "    blend_ft = yt_alpha_blend(wrp, wrp_ft_pred)\n",
    "    cv2.imshow('Classical: SIFT', blend_ft.astype(np.uint8))\n",
    "    # blend_raw = yt_alpha_blend(wrp, img)\n",
    "    # cv2.imshow('Raw', blend_raw.astype(np.uint8))\n",
    "\n",
    "    img, wrp = image_to_tensor(img, keepdim=False).to(device, torch.float)/255, image_to_tensor(wrp, keepdim=False).to(device, torch.float)/255\n",
    "    duv_deep = model(img, wrp)\n",
    "    uv_deep = image_edges(img)\n",
    "    H_deep = four_point_homography_to_matrix(uv_deep, duv_deep)\n",
    "    wrp_deep_pred = warp_perspective(img, torch.inverse(H_deep), img.shape[-2:])\n",
    "    blend_deep = yt_alpha_blend(wrp, wrp_deep_pred)\n",
    "    blend_deep = tensor_to_image(blend_deep)\n",
    "    cv2.imshow('Deep: Resnet34', blend_deep)\n",
    "\n",
    "    cv2.imshow('marked_img', marked_img)\n",
    "    cv2.imshow('crp', buffer[-1])\n",
    "    cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}