{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Homography Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import torch\n",
    "from lightning_modules.homography_imitation import ConvHomographyPredictorModule\n",
    "from utils.io import load_yaml\n",
    "\n",
    "def heichole(resnet: int=18):\n",
    "    if resnet == 18:\n",
    "        checkpoint_prefix = \"/media/martin/Samsung_T5/logs/miccai/final/heichole/resnet18/version_1\"\n",
    "        checkpoint = \"checkpoints/epoch=32-step=11715.ckpt\"\n",
    "    elif resnet == 34:\n",
    "        checkpoint_prefix = \"/media/martin/Samsung_T5/logs/miccai/final/heichole/resnet34/version_3\"\n",
    "        checkpoint = \"checkpoints/epoch=48-step=17395.ckpt\"\n",
    "    elif resnet == 50:\n",
    "        checkpoint_prefix = \"/media/martin/Samsung_T5/logs/miccai/final/heichole/resnet50/version_1\"\n",
    "        checkpoint = \"checkpoints/epoch=36-step=13135.ckpt\"\n",
    "    return checkpoint_prefix, checkpoint\n",
    "\n",
    "def cholec80(resnet: int=18):\n",
    "    if resnet == 18:\n",
    "        checkpoint_prefix = \"/media/martin/Samsung_T5/logs/miccai/final/cholec80/resnet18/version_2\"\n",
    "        checkpoint = \"checkpoints/epoch=39-step=78400.ckpt\"\n",
    "    elif resnet == 34:\n",
    "        checkpoint_prefix = \"/media/martin/Samsung_T5/logs/miccai/final/cholec80/resnet34/version_2\"\n",
    "        checkpoint = \"checkpoints/epoch=40-step=80360.ckpt\"\n",
    "    elif resnet == 50:\n",
    "        checkpoint_prefix = \"/media/martin/Samsung_T5/logs/miccai/final/cholec80/resnet50/version_2\"\n",
    "        checkpoint = \"checkpoints/epoch=52-step=103880.ckpt\"\n",
    "    return checkpoint_prefix, checkpoint\n",
    "\n",
    "\n",
    "checkpoint_prefix_predictor, checkpoint_predictor = cholec80(50)\n",
    "\n",
    "predictor_config = load_yaml(os.path.join(checkpoint_prefix_predictor, \"config.yml\"))\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "predictor = ConvHomographyPredictorModule.load_from_checkpoint(\n",
    "    os.path.join(checkpoint_prefix_predictor, checkpoint_predictor), **predictor_config[\"model\"]\n",
    ")\n",
    "predictor.to(device)\n",
    "predictor = predictor.eval()\n",
    "predictor.freeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Homography Estimator and Taylor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.processing import TaylorHomographyPrediction\n",
    "from lightning_modules.homography_regression import DeepImageHomographyEstimationModuleBackbone\n",
    "\n",
    "def ae_cai():\n",
    "    checkpoint_prefix = \"/media/martin/Samsung_T5/logs/ae_cai/resnet/48/25/34/version_0\"\n",
    "    checkpoint = \"checkpoints/epoch=99-step=47199.ckpt\"\n",
    "    return checkpoint_prefix, checkpoint\n",
    "\n",
    "\n",
    "checkpoint_prefix_estimator, checkpoint_estimator = ae_cai()\n",
    "\n",
    "estimator_config = load_yaml(os.path.join(checkpoint_prefix_estimator, \"config.yml\"))\n",
    "\n",
    "estimator = DeepImageHomographyEstimationModuleBackbone.load_from_checkpoint(\n",
    "    os.path.join(checkpoint_prefix_estimator, checkpoint_estimator), **estimator_config[\"model\"]\n",
    ")\n",
    "estimator.to(device)\n",
    "estimator = estimator.eval()\n",
    "estimator.freeze()\n",
    "\n",
    "taylor_predictor = TaylorHomographyPrediction(order=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from kornia import tensor_to_image\n",
    "from kornia.geometry import resize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from datasets import ImageSequenceDataset\n",
    "from utils.processing import frame_pairs\n",
    "from utils.io import load_yaml\n",
    "from utils.viz import create_blend_from_four_point_homography\n",
    "\n",
    "server = \"local\"\n",
    "server = load_yaml(\"../../config/servers.yml\")[server]\n",
    "database = server[\"database\"][\"location\"]\n",
    "\n",
    "def pickle_path(name: str, window: int):\n",
    "    prefix = \"\"\n",
    "    motion_pickle = \"\"\n",
    "    if name == \"heichole\":\n",
    "        prefix = \"heichole_single_frames_cropped\"\n",
    "        motion_pickle = f\"23_03_07_motion_label_window_{window}_frame_increment_5_frames_between_clips_1_log_test_train.pkl\"\n",
    "\n",
    "    return prefix, motion_pickle\n",
    "\n",
    "prefix, motion_pickle = pickle_path(\"heichole\", 1)\n",
    "df = pd.read_pickle(os.path.join(database, prefix, motion_pickle))\n",
    "\n",
    "# get a single video, also check 23_03_01_dataset_sizes.ipynb\n",
    "test_vid_idcs = df[df.train == False].vid.unique().tolist()\n",
    "df = df[df.train == False].groupby(\"vid\").get_group(test_vid_idcs[2])[20000:30000]\n",
    "# print(df)\n",
    "\n",
    "seq_len = 15\n",
    "frame_increment = 5\n",
    "\n",
    "ds = ImageSequenceDataset(\n",
    "    df=df,\n",
    "    prefix=os.path.join(database, prefix),\n",
    "    seq_len=seq_len,\n",
    "    frame_increment=frame_increment,\n",
    "    frames_between_clips=frame_increment,\n",
    ")\n",
    "\n",
    "dl = DataLoader(ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "preview_horizon = 1\n",
    "cnt = 0\n",
    "for batch in tqdm.tqdm(dl):\n",
    "    imgs, imgs_tf, frame_idcs, vid_idcs = batch\n",
    "    B, T, C, H, W = imgs.shape\n",
    "    imgs = imgs.to(device).float() / 255.\n",
    "\n",
    "    recall_horizon_imgs = imgs[:, :-preview_horizon]\n",
    "    recall_horizon_imgs = recall_horizon_imgs.reshape(B, -1, H, W)\n",
    "    recall_horizon_imgs = recall_horizon_imgs\n",
    "\n",
    "    # predict camera motion\n",
    "    with torch.no_grad():\n",
    "        duvs_predicted = predictor(recall_horizon_imgs)\n",
    "\n",
    "    # estimate camera motion for taylor\n",
    "    imgs_i, imgs_ip1 = frame_pairs(recall_horizon_imgs.view(B, -1, C, H, W))\n",
    "    with torch.no_grad():\n",
    "        duvs_estimated = estimator(imgs_i.view(-1, C, H, W), imgs_ip1.view(-1, C, H, W))\n",
    "        duvs_estimated = duvs_estimated.view(B, T-1-preview_horizon, 4, 2)\n",
    "\n",
    "    # taylor predict camera motion\n",
    "    duvs_taylor_predicted = taylor_predictor(duvs_estimated.cpu())\n",
    "    duvs_taylor_predicted = duvs_taylor_predicted[:, -preview_horizon:].to(device)\n",
    "\n",
    "    # visualize predictor\n",
    "    recall_horizon_imgs = recall_horizon_imgs.reshape(B, -1, C, H, W)\n",
    "    blends = create_blend_from_four_point_homography(recall_horizon_imgs[:, -1], imgs[:, -1], duvs_predicted)\n",
    "    blend = resize(blends[0], [480, 640]) #zeros batch\n",
    "    blend = (tensor_to_image(blend, keepdim=False)*255.).astype(np.uint8)\n",
    "    cv2.imwrite(f\"/media/martin/Samsung_T5/23_02_20_miccai_measurements/eval/23_03_08_blends/deep/img_{cnt}.png\", blend)\n",
    "\n",
    "    # visualize taylor 1st order\n",
    "    blends = create_blend_from_four_point_homography(recall_horizon_imgs[:, -1], imgs[:, -1], duvs_taylor_predicted[0])\n",
    "    blend = resize(blends[0], [480, 640]) #zeros batch\n",
    "    blend = (tensor_to_image(blend, keepdim=False)*255.).astype(np.uint8)\n",
    "    cv2.imwrite(f\"/media/martin/Samsung_T5/23_02_20_miccai_measurements/eval/23_03_08_blends/taylor/img_{cnt}.png\", blend)\n",
    "\n",
    "    # # visualize identity\n",
    "    # blends = create_blend_from_four_point_homography(recall_horizon_imgs[:, -1], imgs[:, -1], torch.zeros_like(duvs_predicted))\n",
    "    # blend = resize(blends[0], [480, 640]) #zeros batch\n",
    "    # blend = (tensor_to_image(blend, keepdim=False)*255.).astype(np.uint8)\n",
    "\n",
    "    # cv2.imwrite(f\"/media/martin/Samsung_T5/23_02_20_miccai_measurements/eval/23_03_08_blends/identity/img_{cnt}.png\", blend)\n",
    "    \n",
    "    cnt += 1\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Homography Prediction and Safe Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
