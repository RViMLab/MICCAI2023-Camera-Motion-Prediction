{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import torch\n",
    "from lightning_modules.homography_imitation import ConvHomographyPredictorModule\n",
    "from utils.io import load_yaml\n",
    "\n",
    "def heichole(resnet: int=18):\n",
    "    if resnet == 18:\n",
    "        checkpoint_prefix = \"/media/martin/Samsung_T5/logs/miccai/final/heichole/resnet18/version_1\"\n",
    "        checkpoint = \"checkpoints/epoch=32-step=11715.ckpt\"\n",
    "    elif resnet == 34:\n",
    "        checkpoint_prefix = \"/media/martin/Samsung_T5/logs/miccai/final/heichole/resnet34/version_3\"\n",
    "        checkpoint = \"checkpoints/epoch=48-step=17395.ckpt\"\n",
    "    elif resnet == 50:\n",
    "        checkpoint_prefix = \"/media/martin/Samsung_T5/logs/miccai/final/heichole/resnet50/version_1\"\n",
    "        checkpoint = \"checkpoints/epoch=36-step=13135.ckpt\"\n",
    "    return checkpoint_prefix, checkpoint\n",
    "\n",
    "checkpoint_prefix, checkpoint = heichole(34)\n",
    "\n",
    "config = load_yaml(os.path.join(checkpoint_prefix, \"config.yml\"))\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "module = ConvHomographyPredictorModule.load_from_checkpoint(\n",
    "    os.path.join(checkpoint_prefix, checkpoint), **config[\"model\"]\n",
    ")\n",
    "module.to(device)\n",
    "module = module.eval()\n",
    "module.freeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from kornia import tensor_to_image\n",
    "from kornia.geometry import resize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from datasets import ImageSequenceDataset\n",
    "from utils.io import load_yaml\n",
    "from utils.viz import create_blend_from_four_point_homography\n",
    "\n",
    "server = \"local\"\n",
    "server = load_yaml(\"../../config/servers.yml\")[server]\n",
    "database = server[\"database\"][\"location\"]\n",
    "\n",
    "def pickle_path(name: str, window: int):\n",
    "    prefix = \"\"\n",
    "    motion_pickle = \"\"\n",
    "    if name == \"heichole\":\n",
    "        prefix = \"heichole_single_frames_cropped\"\n",
    "        motion_pickle = f\"23_03_07_motion_label_window_{window}_frame_increment_5_frames_between_clips_1_log_test_train.pkl\"\n",
    "\n",
    "    return prefix, motion_pickle\n",
    "\n",
    "prefix, motion_pickle = pickle_path(\"heichole\", 1)\n",
    "df = pd.read_pickle(os.path.join(database, prefix, motion_pickle))\n",
    "\n",
    "# get a single video, also check 23_03_01_dataset_sizes.ipynb\n",
    "test_vid_idcs = df[df.train == False].vid.unique().tolist()\n",
    "df = df[df.train == False].groupby(\"vid\").get_group(test_vid_idcs[7])\n",
    "\n",
    "seq_len = 15\n",
    "frame_increment = 5\n",
    "\n",
    "ds = ImageSequenceDataset(\n",
    "    df=df,\n",
    "    prefix=os.path.join(database, prefix),\n",
    "    seq_len=seq_len,\n",
    "    frame_increment=frame_increment,\n",
    "    frames_between_clips=frame_increment,\n",
    ")\n",
    "\n",
    "dl = DataLoader(ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "preview_horizon = 1\n",
    "cnt = 0\n",
    "for batch in tqdm.tqdm(dl):\n",
    "    imgs, imgs_tf, frame_idcs, vid_idcs = batch\n",
    "    B, T, C, H, W = imgs.shape\n",
    "    imgs = imgs.to(device).float() / 255.\n",
    "\n",
    "    recall_horizon_imgs = imgs[:, :-preview_horizon]\n",
    "    recall_horizon_imgs = recall_horizon_imgs.reshape(B, -1, H, W)\n",
    "    recall_horizon_imgs = recall_horizon_imgs\n",
    "\n",
    "    # inference\n",
    "    duvs = module(recall_horizon_imgs)\n",
    "\n",
    "    # visualize\n",
    "    recall_horizon_imgs = recall_horizon_imgs.reshape(B, -1, C, H, W)\n",
    "    blends = create_blend_from_four_point_homography(recall_horizon_imgs[:, -1], imgs[:, -1], duvs)\n",
    "    blend = resize(blends[0], [480, 640]) #zeros batch\n",
    "    blend = (tensor_to_image(blend, keepdim=False)*255.).astype(np.uint8)\n",
    "\n",
    "    cv2.imwrite(f\"/media/martin/Samsung_T5/23_02_20_miccai_measurements/eval/23_03_08_blends/img_{cnt}.png\", blend)\n",
    "    cnt += 1\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Homography Prediction and Safe Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
