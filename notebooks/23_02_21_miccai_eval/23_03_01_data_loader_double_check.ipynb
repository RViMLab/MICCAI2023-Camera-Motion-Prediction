{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from utils.io import load_yaml\n",
    "\n",
    "server = \"local\"\n",
    "server = load_yaml(\"../../config/servers.yml\")[server]\n",
    "\n",
    "database_location = server[\"database\"][\"location\"]\n",
    "# database = \"21_11_25_first_test_data_frames\"\n",
    "# pkl_name = \"23_02_24_motion_label_window_1_frame_increment_10_frames_between_clips_1_log_test_train.pkl\"\n",
    "\n",
    "database = \"heichole_single_frames_cropped\"\n",
    "pkl_name = \"23_02_24_motion_label_window_1_frame_increment_5_frames_between_clips_1_log_test_train.pkl\"\n",
    "\n",
    "\n",
    "df = pd.read_pickle(os.path.join(database_location, database, pkl_name))\n",
    "\n",
    "df[[\"vid\", \"frame\"]] = df[[\"vid\", \"frame\"]].astype(float)\n",
    "df = df.sort_values(by=[\"vid\", \"frame\"]).reset_index(drop=True)\n",
    "df[[\"vid\", \"frame\"]] = df[[\"vid\", \"frame\"]].astype(int)\n",
    "\n",
    "for idx, row in df[:20].iterrows():\n",
    "    print(\"folder: \", row.folder, \" file: \", row.file, \" vid: \", row.vid, \" frame: \", row.frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from kornia import tensor_to_image\n",
    "import PIL\n",
    "from IPython.display import Image, display, clear_output, TextDisplayObject\n",
    "\n",
    "from datasets.image_sequence_dataset import ImageSequenceMotionLabelDataset, ImageSequenceDataset\n",
    "\n",
    "seq_len = 10\n",
    "frame_increment = 10\n",
    "frames_between_clips = frame_increment\n",
    "\n",
    "ds = ImageSequenceMotionLabelDataset(\n",
    "    df,\n",
    "    prefix=os.path.join(database_location, database),\n",
    "    seq_len=seq_len,\n",
    "    frame_increment=frame_increment,\n",
    "    frames_between_clips=frames_between_clips,\n",
    "    random_frame_offset=False,\n",
    ")\n",
    "\n",
    "# ds = ImageSequenceDataset(\n",
    "#     df,\n",
    "#     prefix=os.path.join(database_location, database),\n",
    "#     seq_len=seq_len,\n",
    "#     frame_increment=frame_increment,\n",
    "#     frames_between_clips=frames_between_clips,\n",
    "#     random_frame_offset=False,\n",
    "# )\n",
    "\n",
    "for idx, row in ds._df[:20].iterrows():\n",
    "    print(\"folder: \", row.folder, \" file: \", row.file, \" vid: \", row.vid, \" frame: \", row.frame)\n",
    "\n",
    "\n",
    "# for sample in ds:\n",
    "#     imgs, tf_imgs, frame_idcs, vid_idcs = sample\n",
    "\n",
    "#     for img, frame_idx in zip(imgs[-1:], frame_idcs[-1:]):\n",
    "#         img = tensor_to_image(img, keepdim=False)\n",
    "\n",
    "#         display(PIL.Image.fromarray(img))\n",
    "#         print(frame_idx)\n",
    "#         clear_output(wait=True)\n",
    "#         sleep(0.2)\n",
    "\n",
    "    # input()\n",
    "    # clear_output()\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de43f3610355f051a4a7d1ec68e5cd39983800d0bb5000cb4a591287222bab46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
